{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May  4 11:20:39 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 555.42.02              Driver Version: 555.42.02      CUDA Version: 12.5     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA H200                    On  |   00000000:C0:00.0 Off |                    0 |\n",
      "| N/A   33C    P0             81W /  700W |       1MiB / 143771MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gathering storage and job accounting information for user: wchia7\n",
      "\n",
      "  ** Please note that the information and display format of this tool **\n",
      "  ** is subject to change and should *not* be used for scripting.    **\n",
      "\n",
      "\n",
      "\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\n",
      "                                          Welcome to the ICE Cluster!                                           \n",
      "================================================================================================================\u001b[m\n",
      "\u001b[94m * Your Name (as PACE knows it)          :   \u001b[mWen Han Chia                  \n",
      "\u001b[94m * UserID                                :   \u001b[m3370265                       \n",
      "\u001b[94m * Username                              :   \u001b[mwchia7                        \n",
      "\u001b[94m * Your Email (for PACE contact)         :   \u001b[m                              \n",
      "\n",
      "\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\u001b[91m=\n",
      "                                                  ICE Storage                                                   \n",
      "================================================================================================================\u001b[m\n",
      "Filesystem                                             Usage (GB)    Limit\n",
      "Home:/home/hice1/wchia7                                      23.4     30.0  77.8%   \n",
      "Scratch:/storage/ice1/6/5/wchia7                            176.7    300.0  58.9%   \n"
     ]
    }
   ],
   "source": [
    "!pace-quota"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install YOLO package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in /home/hice1/wchia7/.local/lib/python3.10/site-packages (8.3.80)\n",
      "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /storage/ice1/6/5/wchia7/conda_venvs/lizard_class/lib/python3.10/site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /storage/ice1/6/5/wchia7/conda_venvs/lizard_class/lib/python3.10/site-packages (from ultralytics) (3.10.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /home/hice1/wchia7/.local/lib/python3.10/site-packages (from ultralytics) (4.11.0.86)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /storage/ice1/6/5/wchia7/conda_venvs/lizard_class/lib/python3.10/site-packages (from ultralytics) (11.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /storage/ice1/6/5/wchia7/conda_venvs/lizard_class/lib/python3.10/site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /home/hice1/wchia7/.local/lib/python3.10/site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /storage/ice1/6/5/wchia7/conda_venvs/lizard_class/lib/python3.10/site-packages (from ultralytics) (1.15.2)\n",
      "Requirement already satisfied: torch>=1.8.0 in /home/hice1/wchia7/.local/lib/python3.10/site-packages (from ultralytics) (2.6.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /home/hice1/wchia7/.local/lib/python3.10/site-packages (from ultralytics) (0.21.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /home/hice1/wchia7/.local/lib/python3.10/site-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in /storage/ice1/6/5/wchia7/conda_venvs/lizard_class/lib/python3.10/site-packages (from ultralytics) (7.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in /home/hice1/wchia7/.local/lib/python3.10/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /storage/ice1/6/5/wchia7/conda_venvs/lizard_class/lib/python3.10/site-packages (from ultralytics) (2.2.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /home/hice1/wchia7/.local/lib/python3.10/site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in /home/hice1/wchia7/.local/lib/python3.10/site-packages (from ultralytics) (2.0.14)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /storage/ice1/6/5/wchia7/conda_venvs/lizard_class/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /storage/ice1/6/5/wchia7/conda_venvs/lizard_class/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /storage/ice1/6/5/wchia7/conda_venvs/lizard_class/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /storage/ice1/6/5/wchia7/conda_venvs/lizard_class/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /storage/ice1/6/5/wchia7/conda_venvs/lizard_class/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /storage/ice1/6/5/wchia7/conda_venvs/lizard_class/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /storage/ice1/6/5/wchia7/conda_venvs/lizard_class/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /storage/ice1/6/5/wchia7/conda_venvs/lizard_class/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /storage/ice1/6/5/wchia7/conda_venvs/lizard_class/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /storage/ice1/6/5/wchia7/conda_venvs/lizard_class/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /storage/ice1/6/5/wchia7/conda_venvs/lizard_class/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /storage/ice1/6/5/wchia7/conda_venvs/lizard_class/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /storage/ice1/6/5/wchia7/conda_venvs/lizard_class/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
      "Requirement already satisfied: filelock in /storage/ice1/6/5/wchia7/conda_venvs/lizard_class/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/hice1/wchia7/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/hice1/wchia7/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /storage/ice1/6/5/wchia7/conda_venvs/lizard_class/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/hice1/wchia7/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2024.12.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/hice1/wchia7/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/hice1/wchia7/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/hice1/wchia7/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/hice1/wchia7/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/hice1/wchia7/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/hice1/wchia7/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/hice1/wchia7/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/hice1/wchia7/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/hice1/wchia7/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/hice1/wchia7/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/hice1/wchia7/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/hice1/wchia7/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/hice1/wchia7/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/hice1/wchia7/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/hice1/wchia7/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/hice1/wchia7/.local/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /storage/ice1/6/5/wchia7/conda_venvs/lizard_class/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /storage/ice1/6/5/wchia7/conda_venvs/lizard_class/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO \n",
    "import os\n",
    "from IPython.display import display, Image \n",
    "from IPython import display \n",
    "display.clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.3.80\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "print(ultralytics.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model's Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Object Detection Model Inference\n",
    "\n",
    "- Will select object detection model of choice\n",
    "- Run inference on test dataset\n",
    "- Output will be saved to /inference/run/detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_789474_jpg.rf.45bd340a8e44e2c19834b5b80961e580.jpg: 640x640 1 lizard, 2.7ms\n",
      "Speed: 10.4ms preprocess, 2.7ms inference, 75.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_791411_jpg.rf.c695dbf6b3be317b0871b9cdf41c9e75.jpg: 640x640 1 lizard, 2.7ms\n",
      "Speed: 1.2ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_7995064_jpg.rf.dd34031b259231154d644d4a8cd6a5e2.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.7ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_7998833_jpg.rf.26700d552f7c0703f9335d3136b967e5.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8004416_jpg.rf.451418543bc911ab8ff41de884acf42c.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8015088_jpg.rf.6bec66e5707733cfafcac5eca7799f18.jpg: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8021470_jpg.rf.ee6f8167a22ff46b3fe28092bf8375ad.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.7ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8021471_jpg.rf.718ad1dbd7b49e35066e2e6597fa0818.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.7ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8021472_jpg.rf.5a4203b0a0a438141b951a61acf75820.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8021474_jpg.rf.01161d764d636dcd32e192a7620b025f.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8021487_jpg.rf.1d417153fadc87d08621dad327d3dcfc.jpg: 640x640 2 lizards, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8021489_jpg.rf.787a0eba1a53f6933f002aa4076b39e6.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.7ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8021490_jpg.rf.c623b0d4878f9fd8ad6813c12df642b1.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8021504_jpg.rf.e47bd5e1d38f1aa1159da6f89cb8b7fb.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8021506_jpg.rf.11853f8d200cfeaf778d9bbc26064872.jpg: 640x640 2 lizards, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8021508_jpg.rf.a4677aadca835e4cb88ba8f751bc5727.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8040024_jpg.rf.539931a196e691774998cd5fd2af164d.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8052607_jpg.rf.e18477e724daa39872775c6b0344dc64.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8090096_jpg.rf.1f2336902f5354bd1490590d87a728a5.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8090097_jpg.rf.b00ca86d462b69ec84ba602873f475f4.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8094601_jpg.rf.add46d6f847e5802a8974bb221fd9771.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8102044_jpg.rf.68c52487526166cb4f061f9030f3777b.jpg: 640x640 2 lizards, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8104385_jpg.rf.33d2efd72036fca5023e679a88edbf2b.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8109665_jpg.rf.cc63dab54f86b99035b84f1d7655a72d.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8154256_jpg.rf.fea3e3ed939bdf4824d9143bd128d305.jpg: 640x640 1 lizard, 2.5ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8177148_jpg.rf.df2b52b821277f7ebf0e37e5049953e8.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8196983_jpg.rf.c814ac660aa3ffd3acdf8b6bbc8ed4e8.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8202830_jpg.rf.07d30557b2a188eb1099de35f9e0718e.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8205568_jpg.rf.62601229ac8da1e50671edddc5149912.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8240279_jpg.rf.a875bfcf9cb227c023121bf9f64a2a31.jpg: 640x640 (no detections), 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8244333_jpg.rf.21a70486f4bec2c273cfa1d12f61b5f1.jpg: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8255769_jpg.rf.30a7f14e0c8b50418eeb4c93f512540e.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8256607_jpg.rf.ff167969d46f9bc36c408274e2485f8b.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8283720_jpg.rf.45fbd9b8fac5e8a89afa7445a8fb397b.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8341197_jpg.rf.60acffd161ead5d1fe7d2e70d0ba788d.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8342454_jpg.rf.95ba4c6c27052eff1f2461dede1dfa05.jpg: 640x640 (no detections), 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8351529_jpg.rf.2645f7b6dc7e6d42e90f0dad7a2bab49.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8354267_jpg.rf.69ba58c5360d684998fe33a70a815d9d.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8373840_jpg.rf.38ea4beeca70c2af57d31b0cf5d6a924.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8401152_jpg.rf.f2d8acb7ff32fe08e9c328c9ec9feb66.jpg: 640x640 (no detections), 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8401165_jpg.rf.1a4662fc340d1931595f67b0cffd682a.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8431356_jpg.rf.62387ba1fd4f02b3194765aa747ccaa0.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8441726_jpg.rf.2a383110f2f565c7c56ecf9edeed1c7d.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8474505_jpg.rf.067a87583d0695456ca1e57ca84f2bfe.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8486752_jpg.rf.e5830e12aa051f01802714428a23b7f0.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8509631_jpg.rf.fd27e9755f872828b62acca36512da1a.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8515228_jpg.rf.817496c0a748903aea52f50a6b6b7195.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8519260_jpg.rf.454c1c950aa62ee75bb9ec63b74916d2.jpg: 640x640 3 lizards, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8534645_jpg.rf.97179578506868b6d7b51cf784776793.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8536736_jpg.rf.1e1bd17f90bbad9c70d55683234e3bc2.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8537431_jpg.rf.a7f1e402fb5896403232de943a7fabc3.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8539160_jpg.rf.db5c2f738c981831cd36ca55f1574334.jpg: 640x640 (no detections), 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8539303_jpg.rf.e238a8ed07fef59f52fddb1d96fb177a.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8556649_jpg.rf.52450dda8a8be1651e54b68c993fe73e.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_861638_jpg.rf.ef491ea779d6011f4d29ab91fe1e03ce.jpg: 640x640 2 lizards, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8620968_jpg.rf.26b8e3513c40681c765649d5d9681fa0.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8651482_jpg.rf.1cdf3cd66af2a524e3ad89df8406dfaf.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8651485_jpg.rf.06f25d92cb6d93a6d83e82a762a1e188.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8651501_jpg.rf.6f3daeca6ee766fff1371b9c3ca2ccfc.jpg: 640x640 (no detections), 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8656362_jpg.rf.c28c35345a46d3d810ba8af2ab95f999.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8674363_jpg.rf.ef75452d90b00b227cba5dc819be9e14.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8683061_jpg.rf.eedca017e2bb736257205a604fa8dba1.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8697648_jpg.rf.6e8b3615a418087ad5e3060ed577cfc5.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8710880_jpg.rf.9ec7d6f1be132565dfc88e7d72aa46c0.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8712644_jpg.rf.33efc7c09d8d1b7d3c39ec2d746495be.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8712646_jpg.rf.ea5f91b1b63d2cc62a383c5d3a7d6d2d.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8722799_jpg.rf.2fbc740f1059c21e1d1e8712687d27d6.jpg: 640x640 2 lizards, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8727766_jpg.rf.1659388339fb6eca9eb0499b202b20cc.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8734017_jpg.rf.5fbb0cf08c53d1570d4efa92774d4e56.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8744452_jpg.rf.80a7631e49028e58a53eac098dc867ca.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.7ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8753687_jpg.rf.091b112ccb2125aa4107069c12d97223.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8771003_jpg.rf.00cb911756d057f1c66cf84e360a0c1e.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8781562_jpg.rf.7603d0582d30ff1a931ff0032400fb10.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8792644_jpg.rf.ab1e0de0408319184f73d6cd192f9981.jpg: 640x640 1 lizard, 2.3ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8796175_jpg.rf.f3ebb6a1a8df39394a60ff35ff050d36.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8803647_jpg.rf.a1bca10fa12eb318a9742ab6c1eb54a9.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8829018_jpg.rf.3dc294d238f8b8871a9258683e67bf6a.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_886163_jpg.rf.a9d38cb8d58b597a856c6b3f0d2f0790.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8867086_jpg.rf.3e7fb2d0d2d0aff573de9b552936107e.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8871956_jpg.rf.4d63aee7df98a4a40ca8088b10feb532.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8881140_jpg.rf.016b8a9824002191a8df36a1759e9e4c.jpg: 640x640 2 lizards, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8892807_jpg.rf.82635f476cc23779bcf5fdfa9834e683.jpg: 640x640 2 lizards, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8896385_jpg.rf.fab2c2b2fce757f473558c2b18b26242.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8934928_jpg.rf.a508f1b6c4bbaf08f1e30809c7b0ada3.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8935857_jpg.rf.20073067e373ea760b27d660a3c8b137.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_8990204_jpg.rf.4c4f510f7673b6664517c0eb4979a534.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9010066_jpg.rf.740fd6914fef149af638c6c0dc1ec612.jpg: 640x640 2 lizards, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9011509_jpg.rf.665cd48728ae75519bac97729af5bde7.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9030857_jpg.rf.702ac0c561a41b52e18e5dfc23fcb745.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9032576_jpg.rf.1c6fb09e582b98ed9cf89e3aa3e3b039.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9049155_jpg.rf.d7e440b3fbcab9204c58c0a191efd537.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_905499_jpg.rf.9ae92b0ce16c6d1504d555af164e4aa3.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_905536_jpg.rf.96a4643ca0a8ce9edac553bb23a0ef0f.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_905559_jpg.rf.e0764817019290f75f32465dd991c679.jpg: 640x640 2 lizards, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9064930_jpg.rf.ba94b3a3115f98a211059cc3eec5f1ee.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_906838_jpg.rf.68097837c244e2b9ff9c53ec6a7b6327.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9074806_jpg.rf.6cb90191da934ed2ac8d877deb8e4773.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9087154_jpg.rf.edfb4122770ee68bf13974f2508f4bb1.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9087555_jpg.rf.216a9b37686ea914fc65c6395721582b.jpg: 640x640 1 lizard, 2.4ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9141327_jpg.rf.1030dc48b4ed45f292f656e6ab3d2809.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9141338_jpg.rf.5835d701c296edec50475b5f45cfd6af.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9142112_jpg.rf.8833e1cf832e264c140ebca1b1457303.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9145435_jpg.rf.cf49345ebc732f66207a70468a48479d.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9163242_jpg.rf.45cbf5bd3fa6e4bac064752dc5a54efe.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9172305_jpg.rf.cccbad4d94d18ff050252f783c6f57db.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9181731_jpg.rf.78ec1dbc3757529d3d257883225805bc.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9214333_jpg.rf.d02710885de5dfd4130c93a1decc8542.jpg: 640x640 3 lizards, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9218211_jpg.rf.2c3f47edde16f41be0845f74213d3146.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9218671_jpg.rf.9a6a95148c13973427fd6876bb0e2ae4.jpg: 640x640 2 lizards, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9242955_jpg.rf.b47e22ea9180cc8d58088774d1aa1cca.jpg: 640x640 2 lizards, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9251242_jpg.rf.acfbd3070b5b744713fcb011166eb6f7.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9252760_jpg.rf.aba6e52edaa3236a0851be4c6d6a9579.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9253104_jpg.rf.18b2d7e7dc148b2fa0f6e455630ab05c.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9261937_jpg.rf.7eac09bceb7b65e23c217a4f3e3f0b46.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9261989_jpg.rf.356dcb4c526217818efd42fa4a10c319.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9263060_jpg.rf.3da5740cf4370251432563d1b8507f7c.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9273447_jpg.rf.f06ded89bcfe76b53f9be25c61c477b1.jpg: 640x640 (no detections), 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9275232_jpg.rf.f320f5413b4c5d8213859da09debdcd6.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9275419_jpg.rf.4109dfd4c7a1ea0645fafb88fa81c147.jpg: 640x640 (no detections), 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9275423_jpg.rf.99788cefeaf210c5212910a7e2b45306.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9275464_jpg.rf.7ad2edd16b33ee0a5d3be18887c45488.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9282151_jpg.rf.242673ac2c0ccc5f6accb89ced4f24e3.jpg: 640x640 2 lizards, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9287485_jpg.rf.720cd14a1f8b2425b2e6a7cac8cd5352.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9298632_jpg.rf.5673a3fe0796b6e29aba713118549c9d.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9301325_jpg.rf.b47fef19336ad246f32b5d1e8940991d.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9323175_jpg.rf.a5b7db3fb5a2ccb670d2035b32d96fc6.jpg: 640x640 2 lizards, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9326073_jpg.rf.15c7873024137861b4953ae562344b9d.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9355175_jpg.rf.8bf1d291b97ed471adcdf9d30f0d0757.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9355178_jpg.rf.45a2046c7c4d5d553dcc9f02708df444.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9360917_jpg.rf.c91d341e56970a734bed42d191dbe39e.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9378220_jpg.rf.1bbc07be4f79087f3ef7c8c3fd72e84c.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9379665_jpg.rf.efd9302d49d6f221419333da30ae7fb9.jpg: 640x640 3 lizards, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9380051_jpg.rf.37ce3d8f32157e7a9921ff5ba9ffeded.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9387825_jpg.rf.61d9161e05a90731ec7208cb7ca2ae4d.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9394090_jpg.rf.18aafff71365b5af079f7229fde8ebd9.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9449061_jpg.rf.6e4e9fbdce67558b7546bad95c428292.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9449523_jpg.rf.6e7fb3ebb9db0bb2d225f63313365da8.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9449527_jpg.rf.59b65a69495a1c25fcbcce576eb332cc.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9477108_jpg.rf.f3b0b0c79a8490e6bae643f76b62e06c.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9477854_jpg.rf.9f6e71bd36c759f3ea740da385e4c164.jpg: 640x640 2 lizards, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9478068_jpg.rf.454c60049c9ce0bafa7fd09bc656f610.jpg: 640x640 2 lizards, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9510976_jpg.rf.18adebcb8af45d12fc0f018b2a935441.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9534796_jpg.rf.0c5913e7a6ff33f48ff8d1c6595e0d68.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9535656_jpg.rf.904d79f29a9df45f2b40acd451360458.jpg: 640x640 3 lizards, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9542318_jpg.rf.6bd1d3ca6eba3d43061a293d9f0d9de6.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9545854_jpg.rf.a0720388dabeebdc61a16ff38bf8f326.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9556851_jpg.rf.d30bc99451063758c32fa9d20d07b37f.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9564373_jpg.rf.c3505671ddcf00bf0f43fcdcb7b07a67.jpg: 640x640 1 lizard, 2.5ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9564433_jpg.rf.7b7ff7728512291384f5903e9303becf.jpg: 640x640 (no detections), 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9565133_jpg.rf.628f6826230685583adf0f139e97baf8.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9589885_jpg.rf.0a5ab466b0f790b7d04aeb4c98a7d4d6.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9602678_jpg.rf.4e5001cc2a0f247ebe7ce8d14d841c42.jpg: 640x640 (no detections), 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9603003_jpg.rf.42ff55225e22dcd666948f865333c89c.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9605729_jpg.rf.a9ecf4e709f434e0706a7a9a1dcacf75.jpg: 640x640 (no detections), 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9639176_jpg.rf.53b8f3240903b8dd50118492853944c7.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9650944_jpg.rf.b1db315101cdddba23b4f11373b6696e.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9651545_jpg.rf.e0a797a19dfb83e41a825060b01666c1.jpg: 640x640 2 lizards, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9682257_jpg.rf.f7b7eeef591b6b6ee71e03a7e9230c5f.jpg: 640x640 2 lizards, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9683370_jpg.rf.03e47fba64328562c90f8a826f9213a4.jpg: 640x640 2 lizards, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9694781_jpg.rf.02fbf69f2da2e1dea26437506280c6cc.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9698482_jpg.rf.3df262dcd65bdbe1f9e469de1bddf078.jpg: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9704404_jpg.rf.4bd26bdf338f7bfefabdf869c56fa772.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9730109_jpg.rf.bdf3fa3a068759bf33756e928713bdb9.jpg: 640x640 2 lizards, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9740865_jpg.rf.402e77065a60bf29adfa6a4c10e1416f.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9754301_jpg.rf.1999c7a3c5e4d17125f6e2154d7ddd90.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9754505_jpg.rf.89c2d928de5f67da606f138b12403dde.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9757088_jpg.rf.20b2a5fa1193eb3ae13a0d4cd7d06555.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9781731_jpg.rf.d39fa86bb0d3036a53536331e24a98ea.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9782182_jpg.rf.9d01c69a2e5f22668d4c9348e634054d.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9782396_jpg.rf.777db99ef2d4c98a4e8fae699de5c94d.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9782476_jpg.rf.c662d222881da7adb7bc85402b578a46.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9783553_jpg.rf.98a4f1258271986bd1504d796b2099f4.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9796520_jpg.rf.d04ed1d0b07e0bdda9835262f2446af9.jpg: 640x640 2 lizards, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9796816_jpg.rf.35d84d7be28b27044e39423c05bf974c.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9809746_jpg.rf.add5e5a46fd48ab431b408afe4a01fd5.jpg: 640x640 (no detections), 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9809992_jpg.rf.59774ad8976b6a234764ff2b3e11f317.jpg: 640x640 2 lizards, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9814499_jpg.rf.628d9d8768ec7aca5d16476fee30c36e.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9816188_jpg.rf.0d17fdb546af8bcaa16392652f6cecf0.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9823772_jpg.rf.d736264b0f62aafd7968a998398727ae.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9824042_jpg.rf.985264743ce266f74939152d7eb523e2.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9824952_jpg.rf.2d57b65fea2dfd21841d692b597f9b3b.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9824978_jpg.rf.d493637e3c583aa413a4578cdb58d5ae.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9826357_jpg.rf.01c44a1c02d2ded065e3073878aae350.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9826599_jpg.rf.f1265acc91797e0a201d25d0488427e9.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9827303_jpg.rf.46d7b63ccebb9b89074d134e04a017fd.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9847105_jpg.rf.3e808087bdee1ccba1678c41b94dd9d8.jpg: 640x640 2 lizards, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9849877_jpg.rf.a2923ec4c8063097ef906b73ed2b4d7e.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9872960_jpg.rf.f65bcd90a511eb84424971c846668705.jpg: 640x640 2 lizards, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9875775_jpg.rf.d8c0f21d1c3480be3037b304adfddc1f.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9876067_jpg.rf.36854ae9dada364b65caf60667baf979.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9878295_jpg.rf.36fd37d2ea370683de495b99573f5b1d.jpg: 640x640 2 lizards, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9878303_jpg.rf.3daa55174c6f10de626868f0bd5e6a35.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9878970_jpg.rf.6ee01d4759cbfea4900f95f6fa48295b.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9879625_jpg.rf.4a8a8d4b790c412a767527e2c96b76b7.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9879678_jpg.rf.f1cfda6e54af66a66087ea8c2f16684e.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9879680_jpg.rf.36bc9da327ca11585484b9f7df8f676c.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: brown_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/116461_9879693_jpg.rf.2a38bcc643772e07eda0033514283ab1.jpg: 640x640 1 lizard, 2.6ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_75619111_jpg.rf.b22be798b0f97841d57ccb822d26f2ce.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_75652997_jpg.rf.4d9b916ae4bcfde5353a849253ae8fc2.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_75708778_jpg.rf.5909eb04b2dca3bc06448866d1b48fd7.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_7586141_jpg.rf.e2455b787bd91590d15645f0fc79ad4d.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_7586214_jpg.rf.5799734e988d19becc423d4e350f27c3.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_76008700_jpg.rf.1c6ffe3c75c6da723296b77e4b3342ab.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_76234103_jpg.rf.b77aff900ae7b7cb7ed65de7d023a6b4.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_76595056_jpg.rf.555534ad4df82fe303f76dc0cf30af74.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_76742366_jpg.rf.72484d8294104603fde6921124a0f403.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_76820471_jpg.rf.1fa4b39adbecb56625911c4b1967090a.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_76936880_jpg.rf.1bef4e4fb833e52f2eab33558381329a.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_77005589_jpg.rf.d56d6b1101e41f89f1e1d846e3e8d658.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_77082780_jpg.rf.2a42036aa9f0e568fc0e3a6f8e373c13.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_77184263_jpg.rf.e41dc38e412bf87481a834d4f1f191f9.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_77636805_jpg.rf.2fb106199df58de5873ded4b4ffc61be.jpg: 640x640 2 lizards, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_77649691_jpg.rf.faef2fd86236d15ddf96a00bb193eb35.jpg: 640x640 (no detections), 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_77652627_jpg.rf.b2ca3e05e28b9855564049ea0f63097a.jpg: 640x640 2 lizards, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_77652910_jpg.rf.f55efb88e27fd7e0428c600e60a5d745.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_77776146_jpg.rf.00b70501ca3f52fab5c46bb0f77f35d5.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_77786137_jpg.rf.05f072fc7bfba6867189c0d6a886260d.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_77913282_jpg.rf.625d886df374474a3446506a57062d81.jpg: 640x640 2 lizards, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_77977219_jpg.rf.e00be4c60dc28ae19785f864ab0a7194.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_78347858_jpg.rf.e1bab3ef468926a7a75c9b6484acd589.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_78376457_jpg.rf.b9b4c099e8cc9ed112b1313fd76cec44.jpg: 640x640 (no detections), 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: knight_anole\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_78481810_jpg.rf.5dd54d12194ff236fba537a5493b43bf.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_78498048_jpg.rf.4f60dc4523dde2ce80569be072669888.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_7896282_jpg.rf.8cc213bcb9a9609de7718755d48f1b85.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_79294660_jpg.rf.5f92a2deba729b5a06af329ae52fe29f.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_79426531_jpg.rf.7b7c3410f9a5cf1701ca5de949787dbe.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_79714320_jpg.rf.3419ad59d586bf9af32ee91415cadab9.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_79725432_jpg.rf.bd8adf45bf1b28654c782112e5d487b6.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_79980783_jpg.rf.643c30bc4804d477e208946ea1fb2002.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_80067601_jpg.rf.1f327c776c15f50b4f4e006475285b99.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_80090480_jpg.rf.df71872c528c0144c22b504d0a397899.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_80125462_jpg.rf.72f7fe40b78c448e7858d0a2ad8f8bf2.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_80232568_jpg.rf.b9d6508d220b14daac376b6a1675a253.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_80349217_jpg.rf.e1518f95b4b536251607f9e2059e4911.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_80362955_jpg.rf.dbabbcbf857c2809bf24c6b676420dcb.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_80741615_jpg.rf.9052e2cbbbfe0155f9b38e8dcb46dbdf.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_80879714_jpg.rf.1078d222d2948aa008b2da1b044a5484.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_80917467_jpg.rf.69fedb998db5be3a55b702ba6d3e43e7.jpg: 640x640 3 lizards, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_81138504_jpg.rf.ead8dfa249b2f510b2b1fd9727390d73.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_81208165_jpg.rf.f7fc1b67db200f9fe62bd5b3ecf2a5be.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_8122599_jpg.rf.de240951feb77eeb94523936be05d98c.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_81309182_jpg.rf.cb8b84dffcff345c45c68e85cd8e6fc0.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_81351520_jpg.rf.9da061ac823343e803e475060f1487bf.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_81390602_jpg.rf.da6519376d76bb760c358cf376b54df8.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_81505029_jpg.rf.3ac51e594f145c89739557079add1892.jpg: 640x640 2 lizards, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_81774038_jpg.rf.889b6a6065d6cb7ed13d6a6a01f5a16a.jpg: 640x640 1 lizard, 2.4ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_81948771_jpg.rf.d5c22ac95407f28a64a717468b97da10.jpg: 640x640 (no detections), 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_82053467_jpg.rf.39661d07256f3997093480a492ceb33b.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_82450427_jpg.rf.1a93d64c477e3400f623a20767818c0e.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_8249871_jpg.rf.99bbf87cfa88e67cdc991dfe26572581.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_82545095_jpg.rf.51734047696b89bb784d50abeff39e85.jpg: 640x640 (no detections), 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_82735486_jpg.rf.62f8896bd710a2ddca31009365fb99f4.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_82799705_jpg.rf.70f1d09e019a39c5b025a13b715f25b6.jpg: 640x640 (no detections), 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_82950001_jpg.rf.aaa9d3d707ce1f77a9ced4490e6a872e.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_8295351_jpg.rf.4775db92ddc6bbe4aed0019b0168f178.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_82955589_jpg.rf.af0d28c7554d32b8925fe58b0bee4e8d.jpg: 640x640 (no detections), 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_83617274_jpg.rf.715ea8493a5acc285cfbafa2b9c1bfb8.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_83669178_jpg.rf.180ca6e5021be757737ba1ca235f450e.jpg: 640x640 (no detections), 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_83669531_jpg.rf.7c0ffd185f32e58a115a463c272fd2ee.jpg: 640x640 2 lizards, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_84112331_jpg.rf.2987312c88ba035e323f914d014f637c.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_8417286_jpg.rf.569c50a2af5988f9706d5c261d9f3b97.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_8417379_jpg.rf.21ad88974d68c3c5f0ca218f3bb9077f.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_84331639_jpg.rf.239c55ad68a96a08fb9c8e06777e0cf1.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_84331854_jpg.rf.5260b7e18c94d9c7857cc868bdaf79c1.jpg: 640x640 (no detections), 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_8456214_jpg.rf.3bc1a1997d0828d61f4354c4190e34b4.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_84659232_jpg.rf.58816f89d235eb9f12bd84ecb6909bf4.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_84714837_jpg.rf.ec65e39baad9eb887f8243d0c7783288.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_84742854_jpg.rf.f503bfcbe6b48432caa6c9874775c360.jpg: 640x640 (no detections), 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_84967884_jpg.rf.525f116d5e1ec368153f8ec555d9a133.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_8519675_jpg.rf.fa84d5e3ef2d4d3d9c6b0562f0b1ede1.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_85233342_jpg.rf.e2fd9c9ffb9e09d3b31036ab92d6cc9e.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_85341938_jpg.rf.4c09443085f3053df4d9d5d9d29654b1.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_85697242_jpg.rf.648a3c19dc9e2bf58d3de8185277eaa0.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_85779050_jpg.rf.152de175c4787247ad4a4d4eb9217e21.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_85929116_jpg.rf.b123b44fb3e84f6df71e27a5a9ce3fdc.jpg: 640x640 2 lizards, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_86118341_jpg.rf.b5888c87ff6603a59eb7bd729746d9ae.jpg: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_86207200_jpg.rf.7da948654b32ac63cf9fc2ac03f567b3.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_86415651_jpg.rf.b8f75d7f5f228fd8e737fcd230b0d517.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_8644449_jpg.rf.4c2722d4f2151338da86f80d14ee7c9d.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_86565566_jpg.rf.87086efef60895916729f627b6615bd5.jpg: 640x640 2 lizards, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_86651551_jpg.rf.0fcf7d4e767da8370b3e32faf57d0140.jpg: 640x640 (no detections), 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_86704357_jpg.rf.62cb2f0abad23e1bb7d1c32f23c2ca2d.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_86910665_jpg.rf.24018a4a45fbc80f7e2af6f798c5b8ae.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_86947063_jpg.rf.1ee18732813d475b521acfa4e8788b78.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_87295947_jpg.rf.f4a4514840b087c7e9fb72536fc13e95.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_8760300_jpg.rf.7b064a0fce17f6372a2772da483eb363.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_87609698_jpg.rf.ff5cc949c159b485c49c89fa264b8bd3.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_87879250_jpg.rf.d8d77753c5fcc0eb086800e6fb473016.jpg: 640x640 2 lizards, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_88021870_jpg.rf.fe3d91b1378c9ad5ac41c475ede19ce3.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_8803704_jpg.rf.0531d3c8b8d3423a2c5d458431c0a953.jpg: 640x640 2 lizards, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_88125698_jpg.rf.ef881b1ca15ecc4dde7ec2b4b0cf259b.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_88128993_jpg.rf.fba233ab8389dba279b143241a33f349.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_88174141_jpg.rf.59ff4143fb7fa04f01d859ce9ba05a88.jpg: 640x640 3 lizards, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_88254850_jpg.rf.51e8f0516938011fbfa187317a9c43c6.jpg: 640x640 1 lizard, 2.5ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_88264657_jpg.rf.e83672b33b283a878a33b3d7a25f4760.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_88317341_jpg.rf.b00b9342a3e5ab33627d5df7b928b335.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_88578072_jpg.rf.443bbe95c31003cac8d03f28386d9e18.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_88639193_jpg.rf.3999b62845ab0ccc86fc6f211595441c.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_88706541_jpg.rf.d06454307f1e4f33426771cf60a98a58.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_89333279_jpg.rf.d38dbc6bb36ddc0399af1874ee163ce8.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_89424944_jpg.rf.4d260abc1a883fa029811b1660918adc.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_89799786_jpg.rf.52c04c30e2685c48c36dddafc37e1d8e.jpg: 640x640 2 lizards, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_90195159_jpg.rf.7965eda3231ca5b5736853d2e858941d.jpg: 640x640 2 lizards, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_90260455_jpg.rf.c7954661925983cc9c5373b92fa3177f.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_90281558_jpg.rf.3288170a1d6c83a3e4fd468671f9be66.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_90288011_jpg.rf.8b078dd0545ecb7a6ad7c9ba5a1e0634.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_90344911_jpg.rf.4185fd61c6a8e0e62393cf18f0275343.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_90434468_jpg.rf.81fe1919ccf04589664ce5ef5dc0074e.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_90448964_jpg.rf.42d13c8e5aa9707dd68f54ec077a21d1.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_90528264_jpg.rf.abdd16b071128018e100ceb183acf262.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_90586845_jpg.rf.9e88986b0c4e1534fb81e29857b6f3ac.jpg: 640x640 (no detections), 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_90615218_jpg.rf.a043ba3740f9eb3abe68d9b94290d731.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_90939188_jpg.rf.683469118d5e8af481ce731a13ce2e42.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_91175789_jpg.rf.d3ce21d78d5b15a3631b3ae8077dd3e3.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_91198274_jpg.rf.7ee30959d3f3ffd0ae68014c0080eb10.jpg: 640x640 (no detections), 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_91399809_jpg.rf.30d139956243aed396d14e6d6847cd72.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_9140461_jpg.rf.edaba46de93107923078fefe6bd13a34.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_91409938_jpg.rf.530c9cbaa0b7afcc6b631a9d8bf4c2b8.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_91435691_jpg.rf.bcb3a90ba09580ac6b4946470cc3206c.jpg: 640x640 2 lizards, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_91535555_jpg.rf.9c365ab68fa85b29b0bc2aa1e29038ac.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_91547322_jpg.rf.68663d3172cda47d97141429a0fae2fb.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_91740056_jpg.rf.4285c15d0aa3dc8914fdcf43c1917fe3.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_91808600_jpg.rf.027fba6136ba82165d146e94a01c7978.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_92100970_jpg.rf.a5532b1617c836f6ce464a3e094adbaa.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_92388729_jpg.rf.967afdb8f43a87c0a8ca40251077017c.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_92468743_jpg.rf.7a4027961f68e9a6514ac087d4b55477.jpg: 640x640 2 lizards, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_92495148_jpg.rf.48da1d7c640d5c3efd8fa8ab990f10f1.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_92560585_jpg.rf.385fa4750d819b743d268274588f3184.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_92637407_jpg.rf.78693d8aba9c893d7e7ccc0e9cf49816.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_9274850_jpg.rf.634d002bcbc582834824768533a19b9d.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_92824180_jpg.rf.570d7bc339ee0d8351c520c6908a31e5.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_92906293_jpg.rf.e55bec08cbe6863ebe79d319ffc85d0c.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_92971583_jpg.rf.fc65427c6ba5913831f8188abcc50ccd.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_93032064_jpg.rf.f10765fce817a0ca5f0ccae02ccc400e.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_93420825_jpg.rf.a6bf3a02062a8f3e52aece9b6ca8a4b9.jpg: 640x640 2 lizards, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_93493930_jpg.rf.4a4fc9a4b6a6c3d91942f0ac990ce702.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_93773931_jpg.rf.5b26ed56bedc05b049a6961b2d282b9d.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_93777838_jpg.rf.b914108aeeed620d8745f5d5f092a088.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_93804485_jpg.rf.638136377287153e16e8fc4b9f0c9ae6.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_93869490_jpg.rf.fa1f656d47714971e1cbb477bbf36ae2.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_93886143_jpg.rf.aa281a6306b107894410896fbbd1f779.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_94101371_jpg.rf.4b02491dd99f4ce5811e8fed7c34faff.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_94391418_jpg.rf.52b95fc16d01cfc47e1f6faa6f616703.jpg: 640x640 2 lizards, 2.5ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_94470018_jpg.rf.56d9a676ce212de6f321ca9484d7af2b.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_94960399_jpg.rf.1962dc7e743da51c34b727ef90ee18a3.jpg: 640x640 2 lizards, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_9519594_jpg.rf.425345cb67d60c1dfa8d0310d91ef69e.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_95293926_jpg.rf.9ba531b504f9c336eb5d9cef73229ed9.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_95316317_jpg.rf.8ad30b69e751738579d5c4bc54780c09.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_9538375_jpg.rf.0070e2c7f3d065b4aa51418fef854dd5.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_95398091_jpg.rf.345f76cfe0183edbb302a1f213f7849a.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_9552565_jpg.rf.9111735408be5919429c7fa27a0e6cf4.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_95593411_jpg.rf.bb26209a3fb7b720423678e7844c6c81.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_95656610_jpg.rf.a442b030d9d1c00a911a5be50b6063ec.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_95797788_jpg.rf.f0157fbc135ce7c682bec0a4c93c4535.jpg: 640x640 (no detections), 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_95889553_jpg.rf.8125525cdb5ab99d717f9f048d8e893e.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_96121637_jpg.rf.6194590afd66d82361e7250281da39e2.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_96262599_jpg.rf.c57ada2bb36a0bdec5a21b8b8df32b5b.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_96500283_jpg.rf.91f8762ffa29d3a097fbf0eba3469437.jpg: 640x640 (no detections), 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_9663842_jpg.rf.ce41e8ac954aeb8a4d24cea3bc677e53.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_96732137_jpg.rf.a5d8e61bce368687b66d051858c1b821.jpg: 640x640 3 lizards, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_96986892_jpg.rf.903fe0b82e373eb5b64dbbbb4c8eebeb.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_97023199_jpg.rf.63c4f0ebbf009d4daf0e139f80502083.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_97032182_jpg.rf.7e82a59512d568070be1891958a84c95.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_97137690_jpg.rf.f6831f0435eb20cbcec7b75a6ea66ca4.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_97157609_jpg.rf.54a2448e0497265f576603bf76416d4b.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_97202051_jpg.rf.652dd3b2da39675dcb235e3cfb422128.jpg: 640x640 2 lizards, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_97233253_jpg.rf.b79ffd752ed601d248781f04f83b303d.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_9731891_jpg.rf.9a5e3be2f726d032d3ac9c0a1b242902.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_97386129_jpg.rf.a383672a03e9921318a99f3e5eb39503.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_97562261_jpg.rf.c28924686bc34d2d152f8eddffd92237.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_97566123_jpg.rf.4debc32884e1c1aae89340dc8fe18b9d.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_97566311_jpg.rf.2eb25507e9b1848e44358a86c983b7c4.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_97575202_jpg.rf.7b17b068cdf3251def9f814ce9000f41.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.8ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_97648637_jpg.rf.15a39089d87f73567f4042699fe98b47.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_97896700_jpg.rf.c846cb98d7cb41cb748215f1603bcca4.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_98065621_jpg.rf.8ddb1daab6b2bad3a487728f9fd992ba.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_98122369_jpg.rf.4cf5674feb8949960c194855518830ba.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_98153489_jpg.rf.c21b22bb5eaa3e9a7a5835e4a0a09964.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_98157022_jpg.rf.d165e3fe3909e0f9dc442661da9a198e.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_98399706_jpg.rf.2378d83dee401c80980abb7bc42ce9c8.jpg: 640x640 1 lizard, 2.2ms\n",
      "Speed: 0.7ms preprocess, 2.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_98555728_jpg.rf.b122a5519b7b790f90e1cc07f85d9382.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_98563405_jpg.rf.bf2a05161ea10901d4bbf2d94a9dce69.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_98572641_jpg.rf.3447c4bf5f1f08a145e81f0614f36a4b.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_98653914_jpg.rf.30b927151d109a38832ad6d6b5e95cf2.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_98756219_jpg.rf.47b274e5652505b542fc793a33a2b5d6.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_9879782_jpg.rf.688523bdfe0f8dd43a7dabd14f75254b.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_9931138_jpg.rf.cc0f5985f7dadb33ae0a8f478f1ce351.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_9932020_jpg.rf.5f5ea1ef95f88f8eca6ed7872cb831f2.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_99389221_jpg.rf.04d3c141bfb7cf7a4212646f8afcb093.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_99444910_jpg.rf.39874e1bb27b788ab58fda4b89e3c0fe.jpg: 640x640 2 lizards, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_99453159_jpg.rf.7b5f56ee5a6325bfc8da051fe0de0303.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_99463529_jpg.rf.53504b2f321f12851084f1683d159921.jpg: 640x640 1 lizard, 2.5ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_99472126_jpg.rf.d02935f3644b08b7cc5b22a3fc8c2940.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_99557918_jpg.rf.cf6e3a6d76c1fb555f54ab15afedc947.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: knight_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36391_99853198_jpg.rf.a3639ee2d1c1237d970e0ca4d35d995e.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_224261493_jpg.rf.37e125a7b9d08ad7e749054ed9bd80ff.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_22529312_jpg.rf.1795f5999cae3e6f17ec57d4b027c575.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_22529467_jpg.rf.a19684b2535a850d012c949c0ecd6fe8.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_225821080_jpg.rf.dde26127f0a5ade6f8938273ba38a00a.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_226045741_jpg.rf.5275282fa5469aeb3abe806af4caea5a.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_226497687_jpg.rf.3605968704e60ff4b79ca59d14265eef.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_227104692_jpg.rf.22a86ddc3f243df99d6cae61ef511ad6.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_227104859_jpg.rf.b4003965b2aa1d8e3f42c586ffd21036.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_227173692_jpg.rf.c193495a616c2b6de06d92f1bed32f02.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_228822983_jpg.rf.5657e113ac8a9981cd2c3ac30b1feb44.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_228875523_jpg.rf.2e84e36a64e0939d6bcbcd61422db886.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_229108512_jpg.rf.f1dbd0dd5fd3b2f932642f344d51766e.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_229613189_jpg.rf.8cfcd89a327d59f8dca33cfd75f096c1.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_229628260_jpg.rf.6ece50a86ba147283e2ad40469c63876.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_229674838_jpg.rf.a452f3856eb3af580a846614154e321f.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_229738780_jpg.rf.b94da9560204e5c17cf982a45e4d5eae.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_229813993_jpg.rf.bc225631dfa80be3e38360cfe7a91f4f.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_230137383_jpg.rf.68ca53d3b6f38d22ce146c7e3f2282c0.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_230504988_jpg.rf.d239647ac8ec02dda0b9d88ddda1bc97.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_23076351_jpg.rf.55e7af197c81927136dd0845f77b99d1.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_23249450_jpg.rf.00a783460b3e77fede9703f9870a633b.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_233103687_jpg.rf.7e98b2d8772e47c8a18b046f9d2a0a5c.jpg: 640x640 1 lizard, 2.5ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_233339473_jpg.rf.90fd3746e43b46f883501f085d892e4e.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_233801097_jpg.rf.621910c13a1130d0e8636f075347e47c.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_233981046_jpg.rf.736d1c896d9db6e5028ad65154e8aef8.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_234158008_jpg.rf.ae66c4a7222f7231eb77bf2cb002e12c.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_234195226_jpg.rf.5fc94b8563ca5693c803688263c5a25a.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_234782210_jpg.rf.e5318e12b2f2e8bbd41d10135bd37d1a.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_234909385_jpg.rf.1ac597d8e33b3529f583d7bbb2897ec2.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_234938416_jpg.rf.1c7f37b8b289527dc010294044eb28e2.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_235237765_jpg.rf.4f0260da65e17a3556d52fc047d276ad.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_235585046_jpg.rf.9979b71bbb3a9cf54975dfd809bdbd71.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_235700958_jpg.rf.16d74ca8b25fa5d2201b71360248bbff.jpg: 640x640 2 lizards, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_236328216_jpg.rf.75092188dc7f0b00f97acf6ecf68ff60.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_23637397_jpg.rf.123e571e6c09d24adba663ec11b1e240.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_236711235_jpg.rf.54a2984d4597b728738ac9c43ac84b9d.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_236774205_jpg.rf.fbb6215974a2ccb10d291a2a5260bf38.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_236958654_jpg.rf.8ad3407575fd25bb48befa07cf80f9e2.jpg: 640x640 2 lizards, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_23750539_jpg.rf.20a64f20f68e9d755dc67d1d2934457c.jpg: 640x640 2 lizards, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_237520203_jpg.rf.1de477b1b440cbedae1221d243eb3fdb.jpg: 640x640 (no detections), 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_238053730_jpg.rf.8bbdd38358a1739ba38d391971cab8bb.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_238136100_jpg.rf.bcaeb62a15e92e9283bc65ac06824737.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_238485387_jpg.rf.f55b82c458834b20216bfc334cd87e82.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_238590982_jpg.rf.4ffa720afd044525685ea05ff8b3b361.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_238801600_jpg.rf.df5676e57e63abe04fe65a2cde51ccb6.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_238871296_jpg.rf.92cb26ad0523a963576f6db74cfe69a0.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_24907484_jpg.rf.55ad3da922e1e13dc52d336e37a0805d.jpg: 640x640 1 lizard, 2.5ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_2560046_jpg.rf.64ef6a3e074b045ad48e4fded116bad7.jpg: 640x640 2 lizards, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_26296527_jpg.rf.e5484b7d1cfb59db1d4ac26877c993bd.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_27057079_jpg.rf.c9a9e33d98c4838a352ce39527e9d819.jpg: 640x640 (no detections), 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_28452937_jpg.rf.e1fd9e1a72a3fde4252d1457bc644394.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_28915634_jpg.rf.5625f0338292b4700d6987b0b43e3f44.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_2899169_jpg.rf.738439db1620e43cae38315b776bec6d.jpg: 640x640 2 lizards, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_3007742_jpg.rf.eb25d34c72a0a132fb50bf1848456e4d.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_3058290_jpg.rf.128786b95cd0e91357d8c30a6ce142cc.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_308270_jpg.rf.c6e17763de574bf95e2c9a3355f0ad4b.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_3106737_jpg.rf.9030cbee251977d86bb52ee7d17c1375.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_328227_jpg.rf.6027eda77df0b24f39dbfbebc028b98c.jpg: 640x640 3 lizards, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_32833860_jpg.rf.1c4f8c768e9d3fbb9b22e24d835ed0b3.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_33238663_jpg.rf.cacb7185d48fa88c74f085dd0160b2f1.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_33533337_jpg.rf.4d973975b87c5f346a7b3660f4585f04.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_34508905_jpg.rf.9cf419602641ba5190346777b6ea16a0.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_34509377_jpg.rf.654b93eb795be141952530cfec5ff8d7.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_34510429_jpg.rf.c959d353a058e097f8dc8f82ca6a6cec.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_34510665_jpg.rf.a69d206419934bfcb8a5d563363f6135.jpg: 640x640 (no detections), 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_34703952_jpg.rf.61d3ebe930b2f34716ea962ae19f2a05.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_34703977_jpg.rf.4039a2ab9e59be1eabe2a98781d8d55d.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_347121_jpg.rf.fd90b676a97f652d9f487c58ed683f4f.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_34809887_jpg.rf.de0708e3922176ac52b3a14562abb006.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_34810129_jpg.rf.c046315fa9822fcc6bc9b5c45412be18.jpg: 640x640 2 lizards, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_34810206_jpg.rf.a44218195ac9581299bbd34966bc3174.jpg: 640x640 2 lizards, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_34840425_jpg.rf.2fb23285a694bed4dd600f4c5149016e.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_34842937_jpg.rf.181428c8374c08781fb502c231595009.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_34909165_jpg.rf.5dce814e95ff1a52b6800a19ec63bb14.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_34909179_jpg.rf.39c20a0a4ed780f07afb075d9bbc6be2.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_34909283_jpg.rf.9456804b168a29c03a9f52deb31c777d.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_34909471_jpg.rf.e52ae3cc19ecc371fc4ef46a90536781.jpg: 640x640 (no detections), 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_34909605_jpg.rf.71c449acbc3d172eb6fa78af6257bc2d.jpg: 640x640 1 lizard, 2.2ms\n",
      "Speed: 0.7ms preprocess, 2.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_35240352_jpg.rf.d115dcf1d0dbba152608dfa8add08fb3.jpg: 640x640 (no detections), 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_35240391_jpg.rf.d3e3fdb9f8f10d0dc430ef5fdf32129e.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_35240572_jpg.rf.28434883195cac214263c3a892eeb86e.jpg: 640x640 (no detections), 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_35391707_jpg.rf.8f085ae8989a0c45ebd35eaf8d2a7055.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_35733927_jpg.rf.65531785cfe5ba2993ca9c59c28940f5.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_36186050_jpg.rf.3b2b85b3e5fabbaf1d4f5773670f70c9.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_36353992_jpg.rf.93ba239108984a8f16fc524d88322e17.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_36354078_jpg.rf.e0197ee3b5203571f5091fdee58402c5.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_36512522_jpg.rf.4446beabf18112baec3a2ad9b50bdbe6.jpg: 640x640 2 lizards, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_36683662_jpg.rf.3aaec979bf3b6ff717fa0cee56287191.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_36684297_jpg.rf.ba34d83f717f089a908a2159d73f2e9e.jpg: 640x640 (no detections), 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_36685681_jpg.rf.9a40b7aa9979059979ec4a2faf4981ce.jpg: 640x640 (no detections), 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_36685876_jpg.rf.886b8aa640899c36319064e8ba3d692a.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_36922106_jpg.rf.c4532bfc5c065b2737d119d865cab363.jpg: 640x640 (no detections), 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_37014103_jpg.rf.b8a2c3d77375277fafe198f9f053055d.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_37233439_jpg.rf.2b56138aa3986d50b652a4d783938f99.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_37310212_jpg.rf.00c67547a255b4776bfa0e363b1351e3.jpg: 640x640 1 lizard, 2.4ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_37338530_jpg.rf.728756215e65672c9db1bc4e6c7db038.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_37725648_jpg.rf.46b9ce856ec03b48ebc806dd76bbc218.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_3778474_jpg.rf.15acf7c5c121e2a7bca75c003ce5abb4.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_38074885_jpg.rf.dd342722006da7378f44d7029159db1e.jpg: 640x640 2 lizards, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_38180729_jpg.rf.63e5b3f2fe00c5bc96f638b3db11a521.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_38180804_jpg.rf.67d787a1a9d9b5d45992284d347942b5.jpg: 640x640 (no detections), 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_38181025_jpg.rf.a717a90156920c755ae3ec70bce2264e.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_38181036_jpg.rf.e03b03d189c2a6f259d9b9959000fa7b.jpg: 640x640 2 lizards, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_38194095_jpg.rf.b2935d30520465ec1eff8c5443c7489b.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_38223465_jpg.rf.55da96526823734345b1bfa4302950b2.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_38231083_jpg.rf.10bf39fc62b7b9406c55ec0c2761eab4.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_38268806_jpg.rf.3422dcb34b3f686959dc51585ed21b2e.jpg: 640x640 (no detections), 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_38310203_jpg.rf.5a243dfc685cb27d37d774c13c8499af.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_38327195_jpg.rf.c10d0875a8a3e7b185f1e141f4c532c9.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_38335766_jpg.rf.62b0b43817a20b8b4676a1893f5d0800.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_38336709_jpg.rf.e5ede4742920b74ea5695c4b8d4a75d1.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_38435477_jpg.rf.d64bcf892dd262a1db8db87cecbe3f9d.jpg: 640x640 (no detections), 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_38466107_jpg.rf.eb47a02e6aeba66f77f802a5f4d29030.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_38798946_jpg.rf.0b09856caa38e66414082bb11c5cab8d.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_38798969_jpg.rf.fbac49dae1ace7ed3a03c7af65d427dd.jpg: 640x640 2 lizards, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_38804358_jpg.rf.145a20cbb5522c95abca3d4f29f9e8af.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_38804753_jpg.rf.3daeaeec365885eb7415989399da5302.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_38941128_jpg.rf.b3a00a9d0b2b6f7ca9411ca0c59836b9.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_38941597_jpg.rf.ed6bd1c7cd264bea836d2f0983778a10.jpg: 640x640 4 lizards, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_38941623_jpg.rf.c0aace0817815bb4f6535f913e65ef03.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_38941787_jpg.rf.edd12cc4719a893f98b9e01ad5784e7e.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_38942051_jpg.rf.6a44bd1c48cf7f1a41afb75721f4e81d.jpg: 640x640 2 lizards, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_38942052_jpg.rf.8baa98632527c836442e606ded866a6c.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_38942053_jpg.rf.d10d1639667763f76be994d9747aca39.jpg: 640x640 2 lizards, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_38943200_jpg.rf.bfebcb50b7f82606abb5b477d381c570.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_39152041_jpg.rf.bdf5f7b90fc73a5df4db37c12ff33693.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_39153248_jpg.rf.43e801683524277c02109a262701836a.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_39174531_jpg.rf.71d095e1d3da37546b3aac41ddf55803.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_39178922_jpg.rf.f11f2cf46e0705802efc0c2973e95478.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_39178936_jpg.rf.9f4593ae87f8cb17589769001c56046b.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_39182400_jpg.rf.2ec04b2a0dc333d80c807c006b14f5ca.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_39182601_jpg.rf.23fa30cc261a80c5e0bb6eb5306508ce.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_39214413_jpg.rf.8ea92a772e376f70bb6c13cc255ecd2f.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_39214433_jpg.rf.62528a2529c6753350958bafad729155.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_39230087_jpg.rf.d924f81f1a9963c70da3bb011e4ada27.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_39295597_jpg.rf.f942725292661327d2f74100847ad70e.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_39296289_jpg.rf.c894e4246df249dda7643cbec47111d4.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_39332386_jpg.rf.b8b46709ca3b0900d8c06b8546080a5a.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_39407923_jpg.rf.d68833c8520c6a800667cd5fa28164e5.jpg: 640x640 (no detections), 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_39411666_jpg.rf.c0edb47e124b33ddee4425c3fc270d50.jpg: 640x640 2 lizards, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_39647332_jpg.rf.c365d8a735f415c36b1f4c4eb1aa17cc.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_39653159_jpg.rf.15d70afd88b6bd3b6fb7aef31c22f8f0.jpg: 640x640 2 lizards, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_39725629_jpg.rf.26e60e4536e1ff5d10ec75173d5a8890.jpg: 640x640 2 lizards, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_39728621_jpg.rf.e428a95491f54e380172b8cca5fee393.jpg: 640x640 1 lizard, 2.5ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_39728655_jpg.rf.bf1a17e121ff2815ae239bd5b68abe79.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_39728759_jpg.rf.1451c694f608e072631659324c3d7837.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_39776680_jpg.rf.ffa41840021779e82831264baae0f66f.jpg: 640x640 2 lizards, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_39812509_jpg.rf.00e67b508d3d986b72312b84d93abccf.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_39818381_jpg.rf.335c29daa66d19969988fce0440e8f62.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_39818726_jpg.rf.592bb14404db3584a3225eecfd451379.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_39836910_jpg.rf.3c71e05967df286f98edf72399e9a2ac.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_39847635_jpg.rf.05b66d7793bd333f64758e310d620337.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_39848596_jpg.rf.92089b5be399266a7e3aed264af25646.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_39848694_jpg.rf.54cea907f9f9f950e504a475d9f25175.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_39851820_jpg.rf.5d35e0b49cb55a89366eb8d623580ad0.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_39854493_jpg.rf.9a12e18165eaff28019490123393c8b0.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_39854872_jpg.rf.66ede704d1373c04848410e524188406.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_39860568_jpg.rf.bfd5237bbba1fc932d3056b151d546d5.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_39881829_jpg.rf.35540c6e04dd5be4ccf97480669b65c6.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_39882093_jpg.rf.68e7061259aaf260dcfb7e36f117f31a.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_39977180_jpg.rf.32d6f4257337825cdef097d6bc7c1ddb.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_40046966_jpg.rf.1ba0e30a4c4086a0aacd5cf5c21ef9ac.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_40108398_jpg.rf.726576301af124c561a5e4c151c121f8.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_40406501_jpg.rf.c5b511166627af9250cbd57148ff8f5d.jpg: 640x640 (no detections), 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_4064790_jpg.rf.6a04fb75f24edd974762cec370e4d1cd.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_40762015_jpg.rf.6ff11368dfb7f281b139d9449da3a618.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_40898398_jpg.rf.145f654039298141f1402034e39f4627.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_40910004_jpg.rf.22789c4442609bb03f2bda524db86814.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_40910009_jpg.rf.4f72a3837be6f4da72ce8d82eae87a22.jpg: 640x640 2 lizards, 2.4ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_40925350_jpg.rf.1cde1ce0a70de772c59c8a955fd476fb.jpg: 640x640 2 lizards, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_41000203_jpg.rf.b50a1c1e806416f9bf13d7d5b8ebb0f1.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_41019896_jpg.rf.101dd49256aec3fae1bfee55aa1fe866.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_4108228_jpg.rf.dac6af43467b400ab53b7d5df959c623.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_41087963_jpg.rf.f148855ce7ad410dec9613396dea06f3.jpg: 640x640 2 lizards, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_41186042_jpg.rf.ea0651a3bcb547a611fd9c84b77b3a85.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_41186088_jpg.rf.2399cea6a63315d126f722783631bc5c.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_41312288_jpg.rf.34e4be79d1b5eb19a65d6cca86459309.jpg: 640x640 (no detections), 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_41551295_jpg.rf.d84e66f70f2c1f6d6b8d38adaaa47cee.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_4173631_jpg.rf.82469a4dd9190d851fdd733fd3e60128.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_42195491_jpg.rf.03397f0a2a163454e2708d128d12441c.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_42195615_jpg.rf.db88d61e4e45ea4c7108c9d88ec377c1.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_42531363_jpg.rf.28b6476b8fc0d3f50118897b47e93503.jpg: 640x640 2 lizards, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_42531370_jpg.rf.bf957b75e0dfab4bd93e896e3886c12c.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_42531371_jpg.rf.497f379f6c7041f3560b53b8c6efeb95.jpg: 640x640 2 lizards, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_42531375_jpg.rf.9bb7cb629ddcd4cc5cbe2527b16c3c8d.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_42531379_jpg.rf.4f860f010d443fa50d12dca29be7dca5.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_42531386_jpg.rf.b1dd8efea672a95b9921ad131cd4ede3.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_42591031_jpg.rf.907abaa8d16ff86b2e74e67b8263c2a6.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_43156644_jpg.rf.fa90f1c1ea4290c5cbf3544db1b6cce0.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_43504729_jpg.rf.009eb3ea155526ac7f9669a71fbc95d1.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_43506578_jpg.rf.5cc6b0189ef781099784ceac1e0a4137.jpg: 640x640 3 lizards, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_43656607_jpg.rf.88804a5e407c5e1fdff3ba7955180d4b.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_43934817_jpg.rf.46a617c7e40004a959889dccc3dce131.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_43949097_jpg.rf.6a411844cd12066662cbd2c7ce7aa3df.jpg: 640x640 1 lizard, 2.4ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_4396728_jpg.rf.5225bcd6b29fba2bc5a30b777f7cbba8.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: bark_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36455_44086133_jpg.rf.185f96367b51d06061fa8eb68cef8d84.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_74670700_jpg.rf.62b20fe479a2e8de7bbf659d83d09a54.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_75081455_jpg.rf.d033b460bf5de8ccfb7c899e0a10d9ca.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_75082114_jpg.rf.aadc40f2fcb49e8ecd3b162cac924f9d.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_75085176_jpg.rf.924a45b92782c9b4fe4bdd38cda296af.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_75312788_jpg.rf.ae5484631c4fb61034bd1cdfc57fe1e0.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_75331135_jpg.rf.fc4b9c942fc71d4a5cfa2a18f609ef34.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_75379666_jpg.rf.74b5f91901de586471ed7fea6a632af8.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_75432775_jpg.rf.5c7e946a84104ae43bc10b63191ac873.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_75501234_jpg.rf.37f2356ce6f18ab952fd8e9634ae722e.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_76571017_jpg.rf.7801f35cc444ceb4ebd0a0b4ea074a7a.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_76820250_jpg.rf.f3b65f1f15d6da79c38665fe08b1bce7.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_76946064_jpg.rf.6dfa61a5ed8ff125784d79cbb589822e.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_77401403_jpg.rf.8eef09b1a0fb9e0b60119488137c05e2.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_77401649_jpg.rf.5d6837f096f640c704adfcd929611984.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_7747514_jpg.rf.7bd4dd5a16c146641428568925f1ae43.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_77495682_jpg.rf.205b190ea49a8dbc3a796cccf9cc189d.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_77515687_jpg.rf.bfe934c8f2eec6771c12dc7ef40039cb.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_77585520_jpg.rf.dbe4c1ff2a888844b8be6536f9d9a05b.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_77642871_jpg.rf.6fa192c29989249c2af34e70d8832042.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_77649208_jpg.rf.0606312407eeaa9abd0bfe2f5f637103.jpg: 640x640 (no detections), 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_77658863_jpg.rf.c994965ddbf81383dd02f6756cff5e97.jpg: 640x640 (no detections), 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_77742697_jpg.rf.f061f00d07ae53680c3d1eb4bece510b.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_77818953_jpg.rf.86a48cc552716668d414a8c89e738bc5.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_77828280_jpg.rf.cdaef171a9d87786697fdae708806dd8.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_77845172_jpg.rf.1b4dc4e4825c7fb5181e4fb0a3c8bbe8.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_77897248_jpg.rf.ce48e0243a19b367324691b403e1aa0f.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_77934504_jpg.rf.35cc808f113ab3bd8af680e48e26c214.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_78091072_jpg.rf.a79dde4275a4ebcea3be213fed1e397b.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_78307708_jpg.rf.f11560bd59a86be908561b26229e6db1.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_78391712_jpg.rf.bfe03b3b62e9958c4a236dd94c5fd65f.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_78471661_jpg.rf.56c9902bd398259a39b3600b6e547c28.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_78481843_jpg.rf.39306f07addcc3801d8b39cf952db0a2.jpg: 640x640 2 lizards, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_78499025_jpg.rf.50aa086b7a5ce6c9f557bf352b4c140a.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_78526825_jpg.rf.25a4aefa9c02b9b4ee979fcc46c4f213.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_7908707_jpg.rf.c488f98737722f36a1b5030e8a412e47.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_79273866_jpg.rf.4b738b4baa5b457c51862986e0e4d87d.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_7943313_jpg.rf.1c85fbd02a599b9c0ec8c2fa6bdff218.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_79644403_jpg.rf.4e1392fc61ff94e4738f86c6a5204ef8.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_80067186_jpg.rf.060e05302daaf806badd9b7b3f9022ee.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_80087247_jpg.rf.29226ca961937b7daba335c5a4a8388d.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_8021501_jpg.rf.1ab15b7e99ef7bdf32fff2f42c018771.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_8021502_jpg.rf.2e3b028b487007a6f238bd9c71a8b9d1.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_8021625_jpg.rf.ae6cc8867bb1a3cf42f4b0399d481382.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_80369854_jpg.rf.a61aca5d8bcd4d4e50c078b217db8689.jpg: 640x640 (no detections), 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_80371733_jpg.rf.da20c99ec7e1ba89b12e3580f551489d.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_8045710_jpg.rf.7c6127b4f362bd354ce12505efbd8e31.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_8045731_jpg.rf.0aafb4eb96a168da3e2f39f969d2bb24.jpg: 640x640 1 lizard, 2.5ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_8045765_jpg.rf.f48dced5909b91efb69693fde6b77588.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_8045919_jpg.rf.e9be50a43a32dfa736424cca1c986bfe.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_81805618_jpg.rf.bdeadca18d48b520ed0574b55a9716c3.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_81895178_jpg.rf.3c072d49a0fb28de0a9e707df7a66a87.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_8247169_jpg.rf.c8b4e0a689b53d32fbbcd9f0ec34a97e.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_82475316_jpg.rf.aae991a7af0061e21e9d3a9dde22cb12.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_82622884_jpg.rf.0c0acd5618c0956297464362454b9b4b.jpg: 640x640 2 lizards, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_82921413_jpg.rf.6394ec935c91a154387a6ccd16403095.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_83032890_jpg.rf.831341bb84376c1c32797bb5a784bc53.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_8334980_jpg.rf.d80413f88ae7240da430fe370e79136e.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_83567606_jpg.rf.5edfb20034477d4063b492898e387c67.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_83705008_jpg.rf.a3e25a6d95da84bf1ead018b28f8a9d9.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_83707370_jpg.rf.d2e125241e8e6ad2060931c60a04e663.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_83742553_jpg.rf.bbf098dee4fc0bad025f6031fa3cc4b6.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_83962764_jpg.rf.36794698885780654fc108ffac3f54e9.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_8400984_jpg.rf.a7375f1f2181504bb2687192077d38a3.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_8401017_jpg.rf.968ff7917549499136cbacea94e00bb4.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_8401056_jpg.rf.5ceca88170dedc35b847dcb4fbb473ff.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_8401074_jpg.rf.21f0e382c8b565c871b0304c7b01a899.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_8401206_jpg.rf.3c6dcd00fdd26a424ff2b640ae298152.jpg: 640x640 (no detections), 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_8401729_jpg.rf.343c1eb5db77d31223e6b4ac9a9541df.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_84202654_jpg.rf.69837180781cd4772cac63511d6e151b.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_8476571_jpg.rf.2411a613248dc5eb1b29034541cd7b25.jpg: 640x640 2 lizards, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_84838868_jpg.rf.7e7f7e069756f1e873a3afa752ca9f38.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_85053705_jpg.rf.e7f1324be96ecdbd84dc9868282428af.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_85059967_jpg.rf.160fdaea6d3ba921e6d95c307d061d22.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_85134369_jpg.rf.d64cd2d4caff6ea56abf16a25ac12e69.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_85289003_jpg.rf.d5bf80d72177c0b07b021844efa7f885.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_85483047_jpg.rf.0e38144b8d6c3a9a7a3d683e49acce2c.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_85701612_jpg.rf.5726456dd874bef7c691d81930483802.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_8574831_jpg.rf.93b419b0339c41614817e72a078c9e4b.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_85931117_jpg.rf.8aa06564f4a38ddc9422d5900a0ebd1a.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_85943023_jpg.rf.554809133bae33dd7a393760f9477cda.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_85982595_jpg.rf.e909d21cb2917786bbca6d86870aafd3.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_86037862_jpg.rf.b0b593878345ec37b2028ce4f9eb7479.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_86208334_jpg.rf.ff0f9a7f12b23936c80e0055b3b59ba5.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_86208956_jpg.rf.d3b5854aeaeabc6e2b07dea4a0044ee0.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_86279962_jpg.rf.d28a3de3c3878b4649c290e55d569918.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_86462392_jpg.rf.9ef756c36f5a3ea39453a61ef6317edc.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_86489350_jpg.rf.ec899f2b5b56fcfcc038a7e84c85b9ca.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_86604642_jpg.rf.e81be5a48048e70cf356542778997b6d.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_86898482_jpg.rf.8c315656015f181f57343fe5ef3c20a4.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_86981664_jpg.rf.8859f00ded210bf4f2d3fe06c8e63488.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_87319567_jpg.rf.e871ff8fba922d6030c17a74e16919ec.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_87452269_jpg.rf.506048bde133186a580986316fc14b25.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_87569192_jpg.rf.1d81ddeb16139a6b56f9df425038b9fe.jpg: 640x640 (no detections), 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_87627436_jpg.rf.6fc4b16922ade72aef6b07359c38ea25.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_87916795_jpg.rf.0d1270013d8c47600332ecd392b2e15e.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_901021_jpg.rf.a05d18a63475c96eb27f56e5c633a201.jpg: 640x640 1 lizard, 2.4ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_90345468_jpg.rf.5cfedb90ebdcd4f1d76740815563feaa.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_90382167_jpg.rf.9bac0d30cebe4c6c17d76321513b4c3f.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_90424372_jpg.rf.f1f36aa146fe572cd07e4e8953fdf6b3.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_90707272_jpg.rf.291ae9849de81093d7954e8de2eb44ca.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_91329996_jpg.rf.b3065add46e04b777facc160e8999e5d.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_91495801_jpg.rf.b46c94ad75f2a5254e67beef1ac90752.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_91597736_jpg.rf.a58bb496e1b77990d9ca59d9b6c1a85d.jpg: 640x640 2 lizards, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_91857315_jpg.rf.fdfbbd20e393a50230f0603d33eb5f56.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_919013_jpg.rf.c1abbd3f71f4b75e0959af36b0567e00.jpg: 640x640 2 lizards, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_91959201_jpg.rf.65a182c7c0c377085061f239899644e1.jpg: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_91979529_jpg.rf.a3dea6439e2f619d2cd7049879df8744.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_92195440_jpg.rf.095ae6c3e16c1b5dbfdc93bc2b94bf90.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_92514623_jpg.rf.f5c51c7605e39dd5385ab080602fdd1b.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_93152758_jpg.rf.a1eef01be626c4c5aa4aba79581f7b38.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_93281885_jpg.rf.d70ff4df95df97f0103024c50ffde4bf.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_93397135_jpg.rf.30f21c3873cbd90c20c66b0313037bb2.jpg: 640x640 2 lizards, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_9340760_jpg.rf.98aa63c4e11ebb157aecb7dfca003d4b.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_93670493_jpg.rf.48b635ec558219d41c4f514b0195a1cf.jpg: 640x640 2 lizards, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_93828622_jpg.rf.946028e21bf5539ddf1ec07d06e9c63d.jpg: 640x640 2 lizards, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_93883314_jpg.rf.b3667d22f04e342bf63a59a5f18712a5.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_94009183_jpg.rf.894e73e1202f95d8d48ee6145ade19e2.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_9417986_jpg.rf.d8fb416378e896d2d3c8f2111f22e09b.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_94262444_jpg.rf.294b96306d4f8999bdec903dc166ff0d.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_94292332_jpg.rf.3c635d74567ceeadc77a775ed4593ea1.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_94579330_jpg.rf.61f828c0aa8ffe7aa161a9f0d3f90f5e.jpg: 640x640 1 lizard, 2.3ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_94695765_jpg.rf.9c44c6cd01bd536458b7881ddc890c32.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_94899312_jpg.rf.a2804780deeb77feef25499318683a08.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_95147733_jpg.rf.c6016bf28aa3276aadb87e0f7d77e514.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_95212581_jpg.rf.3673d75e8808f660bb8bd49c88eb251f.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_95317737_jpg.rf.7e38950287848f5dc479f3659e45e688.jpg: 640x640 2 lizards, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_95430330_jpg.rf.0645af1b621e0372a7332674ff0b6412.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_9562622_jpg.rf.13796bdc5abd9f4aaf8a9a01a61596eb.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_9567266_jpg.rf.49e9abafaecdc1e75e60254913652b2f.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_95712332_jpg.rf.7ff63685548a94c19ab11289d579366a.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_95813687_jpg.rf.b5ddcae91dd9f411719e84cb07ddc27d.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_95814676_jpg.rf.115313473eb49c3da2047e96bb25a345.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_95815144_jpg.rf.5e69d8d68f6cb3906f9c26015e7619d1.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_95815323_jpg.rf.6fcbff7514de2e5482f002d133728863.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_95815359_jpg.rf.6236021f4db16294bba0678faa9296b3.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_95815604_jpg.rf.a5287cfaaf42151296fa3165b076bd5d.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_95815641_jpg.rf.1b68a1537994dd6f82a673b9c665862e.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_95815670_jpg.rf.926251ac03b456c3cdb3967d89424fc0.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_9596277_jpg.rf.8d690ff73211dcb773c29333833649b8.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_9621392_jpg.rf.4cc192bdbf25a41157fb3e15f5cf35f4.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_96306271_jpg.rf.e62a08b7068ac55aebf394061b8e1207.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_96323006_jpg.rf.afd71f6631cc9156d73c147c789efe6c.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_96323009_jpg.rf.448f3ca49ab3740ad1ccf376b2b6990d.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_9640890_jpg.rf.6a1413f59ad82fdbb9ae384490ee7f3f.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_96415928_jpg.rf.a0ecf85a0ad7a2ec6f0a72363891da90.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_96674004_jpg.rf.160cd4fae4468fc0bdac844c445042f9.jpg: 640x640 1 lizard, 2.4ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_9746062_jpg.rf.b44da045c5a0d1646edbce82ead245ac.jpg: 640x640 2 lizards, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_9747056_jpg.rf.da7649fbc8799a5e666f5aec2727ecc0.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_9750330_jpg.rf.12aa37129412399aa2caa04b04d89d2f.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_9756538_jpg.rf.fd2fa8070d358adcadb08713608725b3.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_9797463_jpg.rf.7aedf8063e1254c5716d7d6eb19d56da.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_9811279_jpg.rf.e17e502b5be3c45f18c842bfae7dc121.jpg: 640x640 2 lizards, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_9815004_jpg.rf.3dceec6e94bc8f3b9b2acbb060e94d94.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_98595254_jpg.rf.a523220cb430eb33ea08c1e02f835ed5.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_98718766_jpg.rf.694d2161e9f85a2775d82d79fefbb1e3.jpg: 640x640 2 lizards, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_98739785_jpg.rf.ba34c27f3b4a014e6b904b5376d08531.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_98830448_jpg.rf.7a9d4bb1ab2cda953d7bbffcd6e019fe.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_9893312_jpg.rf.507d63593cb568e91126dfb30d8924c9.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_9894586_jpg.rf.b7693fc1fae4b5b94cd188118fca207d.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_9909761_jpg.rf.7e21776cb0a243483c29b179906a665e.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_99099360_jpg.rf.f322651f5712592c78acff4a003c6480.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_9910191_jpg.rf.ebf19278172d3cda27d8704005f9ebc0.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_9910262_jpg.rf.3dda21ca8fb2b486089fd2c467fd7004.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_9919458_jpg.rf.f95054a9153f5c9069541ecca8355aa8.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_9921265_jpg.rf.5e40e6f1fe7d068605848b4e5bba70a3.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_9921304_jpg.rf.9d8a3fe81c612619666d6bc252467bc3.jpg: 640x640 2 lizards, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_9922113_jpg.rf.26ebdd05ad704061d19ea168ca1f8879.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_9926949_jpg.rf.b3df198368bdd2496a6419ccb1843a54.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_9927238_jpg.rf.ccf06bbf1128795424e1db645a80952f.jpg: 640x640 2 lizards, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_9927309_jpg.rf.650b5cb7335cfb7fc8ff50347545389b.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_9928808_jpg.rf.0012e7de66f9b2204700017b726668bd.jpg: 640x640 1 lizard, 2.4ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_9931139_jpg.rf.0b738cb75cb5f1739c05561d8ec4d054.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_9931168_jpg.rf.35f500da26c89115a0a654aa7b84af06.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_9935090_jpg.rf.0928141cf61f08fbaab7c90242a60c5a.jpg: 640x640 (no detections), 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_9935451_jpg.rf.c703d65734db5073de327a4658f9815d.jpg: 640x640 (no detections), 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_9935667_jpg.rf.2570f5649046364077419990721bc309.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_9935900_jpg.rf.c30cf71e743e9bc5abb930a6ad52bbfb.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_9937770_jpg.rf.3725464e49015f673ff2ed1d17f5e3ab.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_9937812_jpg.rf.342acbe122a23a4ec4d68cf57626ee1b.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_9937856_jpg.rf.a7488ed8ad4eae39d9601a41d21b3614.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_9937888_jpg.rf.4feeddf9d9eab44f7acf2c478a57faaa.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_9937893_jpg.rf.12492a609517caa7a8e2683f3ec09d1c.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_9937970_jpg.rf.944f124e6afb59f954a9d6be59f49d08.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_9937998_jpg.rf.1a783c9ebbc311a558bffab5a3188da3.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_9938283_jpg.rf.16ca5754a9bf0fed84b3d8fbefe0a4be.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_9938297_jpg.rf.9c878e0da4d270978bd41d6921a48052.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_9938436_jpg.rf.aaa70229183d157a2c43e3727b9d3fef.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_9938503_jpg.rf.b77a55de4585b4b6ef62ab7fdf2f642a.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_9938594_jpg.rf.e175c3d68bf8f2cb1d112d9f6fb1b6a7.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_9940372_jpg.rf.9a726171b8994f7a90c45a224fcfce2f.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_9940597_jpg.rf.e6509d4b0970e9b4e574d7b4526cc388.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_9941006_jpg.rf.d8c9a8efb1787d831ddba572875cd1fa.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_9941039_jpg.rf.ecf26f34e2d915474071a43c944cef1d.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_9945959_jpg.rf.4a171ed4476445d0649953471bce8cee.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_9950192_jpg.rf.e136fbd373a9ffbdd403c9ea589b7035.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class label: crested_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36488_99896177_jpg.rf.305624cc93bdde8747fa6be4714e0ae2.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4203810_jpg.rf.d4ed08476c3e911ebe9acd588115a2c4.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4204312_jpg.rf.594882bb98f5aa0b75e9a103a1578634.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4207229_jpg.rf.efdc1b5fc97b03581733d30456089b66.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4207772_jpg.rf.2eaee2e6b6c3e90a35ad44c772abc67f.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4211023_jpg.rf.23b799c654ea3b0b6529da5d0d4f63bf.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_421208_jpg.rf.0e5d44c9dde653b606fe704a6e750968.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_421350_jpg.rf.b2be05e21b32ee6cf50a370b20ebebb7.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_421597_jpg.rf.d2c0d66f73f53b9966bba9a249decdef.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4218750_jpg.rf.cff76ff304da1fcec246b1cce1ea0f35.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_422197_jpg.rf.79e9d99d1057f1859fe4f6c6620ac006.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4224527_jpg.rf.bf4407dc888d81e81232ec6a2cfc78bc.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4226702_jpg.rf.5e58b932991aa927ad2f82c510c788af.jpg: 640x640 2 lizards, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4226934_jpg.rf.faedf050568afcebdea5b4d60fc39097.jpg: 640x640 2 lizards, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4227674_jpg.rf.1faa1c1a942639bdcd39865edee980cc.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4227932_jpg.rf.29d08e84fdd09bbde406bff24075e981.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4228220_jpg.rf.f3d06b9a7eeba095254452b87b4a951d.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4231203_jpg.rf.278e9800a4fac24c0fc52bb1c1162902.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4231206_jpg.rf.5012b98804c1f26941a8bf14c6b1bec7.jpg: 640x640 (no detections), 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4233739_jpg.rf.0fffe3246727ebc8c9080dcdbbde3e0e.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4237588_jpg.rf.e24c630b8b5a88dc1cb4b9b9896ed388.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4241178_jpg.rf.619a45f504807ca9db6c901abc624cbf.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4241810_jpg.rf.22c8a189a54580811445865b9ddb0076.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4243807_jpg.rf.e2df36803b681bcf5577b07dfda35517.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4245819_jpg.rf.386173c281543ca47c5b762f4f6a77f4.jpg: 640x640 1 lizard, 2.3ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4248904_jpg.rf.cada590629b3e54181f54627475d9103.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4249241_jpg.rf.ba211ae64867fbd7d89445fb4a3877f2.jpg: 640x640 2 lizards, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4250193_jpg.rf.0da5da3a4e74dc37d1eb0aa0557a99a0.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4250660_jpg.rf.ee8f0b5156fc405d65b28a4f84bb7de8.jpg: 640x640 2 lizards, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_425157_jpg.rf.a294a3a2ea7c6aac781605ea0f2fe515.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4256063_jpg.rf.46f0eb439e03b7b4b22d7c6d4b6e5dc0.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4257657_jpg.rf.e863b1c40ffce84140ef512718576cac.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4257671_jpg.rf.2bb0812b95c3daad653d2357933404c8.jpg: 640x640 2 lizards, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4258984_jpg.rf.f66338f8b2ae567e61d68ab94fda7186.jpg: 640x640 2 lizards, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4260558_jpg.rf.3497be122bc1014c15665e173be42f8d.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4262305_jpg.rf.f14726ea2bb1e9fa328ed12252dad2ba.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4265734_jpg.rf.6fdce92a924e43d1871bb9642ae17ee5.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4265853_jpg.rf.33747104e105a89b2e50c93d036d6be6.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4266460_jpg.rf.f5f25171db1214662e7f36d900b18c3a.jpg: 640x640 3 lizards, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4269115_jpg.rf.8ed45efda317f1ef4a271ecb5a7609f7.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4269777_jpg.rf.6e3fb24568bf367b065adfc04bc3fbb3.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4271867_jpg.rf.0efc4b543904b033a1200c264f4b7f80.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4278137_jpg.rf.5b945abb4666f7eb4e4f1526e6626c86.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4278475_jpg.rf.2b8660a8f3bee2d5b096c465bcc7099e.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4286174_jpg.rf.905af42a772c69b1dec24ac377887c22.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4286610_jpg.rf.3e84dbbe507d3eba717f88019b36d2a8.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4290923_jpg.rf.2d9308986c2e8f4399dd7d9542c967f9.jpg: 640x640 2 lizards, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4292151_jpg.rf.e22da5bc9b4ee3d0c301a89d91ed1828.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4292959_jpg.rf.810a9ed25a6b79e4c67d436464cdd78a.jpg: 640x640 2 lizards, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4294106_jpg.rf.df0b2e2e6563b486d23a97c8525ddf7b.jpg: 640x640 1 lizard, 2.6ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4294891_jpg.rf.d7cf370adcb5079cb43440b17a9fb814.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4300539_jpg.rf.8c7df0ab5e09749237b115ba2eba18f4.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4300903_jpg.rf.170d3b6f4aa3a88fad49bf8bf6c362ff.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4304794_jpg.rf.b7612763f65fa497643eacd1f43ba27b.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4305065_jpg.rf.97c5d1253861c7e8df5540f3dd22e954.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4305182_jpg.rf.ee584623f13b78a8770adf4e0408d5d4.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4306887_jpg.rf.4a50b0975926b97a4527be65b3daca54.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4308311_jpg.rf.b1df36b58e6ae46d210058202ea8d055.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4310294_jpg.rf.4db26d3bbc96bf92b81db5d8af2764dd.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4313803_jpg.rf.a50e8b47a54e05fa7ca0c835bd673a4c.jpg: 640x640 2 lizards, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4314321_jpg.rf.fb9f7af745ab3ece8734869485aaad3d.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4314336_jpg.rf.fbb6328f6961b70b6ac23088e19447be.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4315094_jpg.rf.4c5d49e8cfef5bf4ec588771d7bd5196.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4315255_jpg.rf.79383311e4d08842f139490bcfce4237.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4316757_jpg.rf.47312b3471f623cd2869e58495a7c971.jpg: 640x640 2 lizards, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4317586_jpg.rf.a3edae6beb67809c37e52a13d87ecfbc.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_431858_jpg.rf.79815d289799b0e52c3d2c64691378cb.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4319646_jpg.rf.f8dfcb92d108c75436efb97e9ee87963.jpg: 640x640 2 lizards, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4329662_jpg.rf.e37692a37115398555991d9ec53d94a3.jpg: 640x640 (no detections), 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4330095_jpg.rf.29a98c7ca2e9999e152cd41e2fe9a2fd.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4332657_jpg.rf.1050543fbba5b74c8225ce82d029c70c.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4332811_jpg.rf.862cad811ff322c4c03bea85f91dc45b.jpg: 640x640 (no detections), 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4332851_jpg.rf.02a4792ba4fd4406816c87dfbcdb54c9.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4333898_jpg.rf.a31c2fa01941a1bc4455c6f9afc45fec.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4334713_jpg.rf.7fdcee84f4878b2b79d35496e58205cd.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4336233_jpg.rf.3a2ca4f0af9d4a8237148d522b5b7650.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4336386_jpg.rf.8299673b5af7cb698e2f8c6d05431023.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4340402_jpg.rf.42d04dfc7223f0f8b3b36a8e8342663f.jpg: 640x640 2 lizards, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4340404_jpg.rf.7cc413c9235c8cd1ee732f40fd3bbff5.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4342455_jpg.rf.36a0b0b280966a9e812d6b5e9d81545c.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4342823_jpg.rf.c721d21666df7f47cb04ee6325f7f083.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4342981_jpg.rf.dc61508a6e6d1a119880e6c6af2b5535.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4343051_jpg.rf.8eea6c3d1b56e8c4c93f55a1edd0227c.jpg: 640x640 3 lizards, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4343056_jpg.rf.7e7d865487c5b49e656fa4e67fc801b9.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4344347_jpg.rf.05151393747cf05ff8d00f3636a3eb6b.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4345064_jpg.rf.66aa82a71567f8a6f7bc9afa24eadeb3.jpg: 640x640 2 lizards, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4347288_jpg.rf.ff8fa21b98484bf5338e7835ae9e5f98.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4347824_jpg.rf.7e22c58c65150f73ab51f94eefe62fff.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4348390_jpg.rf.828a9decdc49000f59e6de4fef7651b1.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4362117_jpg.rf.4b19f25dc146b5ef27c76d40a1381e20.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4362422_jpg.rf.24f3c2f4877529913ee71d779cb80efb.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4363248_jpg.rf.28ba608d36f29ef007bdcd99264d3a55.jpg: 640x640 1 lizard, 2.2ms\n",
      "Speed: 0.7ms preprocess, 2.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4363848_jpg.rf.dce0cd7235ef55374b62c64abff1d2e3.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4363920_jpg.rf.6c31804a91877ed7f1e6e2b42de7b962.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4364284_jpg.rf.e0f032c1ad5a9626234f2723ac336419.jpg: 640x640 2 lizards, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4365752_jpg.rf.a24c4a91ee5614b8ffd96c6cc25e1b3e.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4366133_jpg.rf.f8aa5baaf12e95163e5c5080abf13fee.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4366910_jpg.rf.c8097f7571565aba2de1f7100e9c8fd2.jpg: 640x640 2 lizards, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4366982_jpg.rf.8e27eb8c4b4ef010ecffacd87b627548.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4369957_jpg.rf.fe7aa1f3c2ae07c775f3e6280603fdc5.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4370382_jpg.rf.a117e370d8b3136c4df632b644c8039a.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4370726_jpg.rf.30431ac57105604af7a68a2ce4c9758e.jpg: 640x640 2 lizards, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4371443_jpg.rf.0e39d53d5972573f1175fb1babe94b2b.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4371612_jpg.rf.8d92231dfe9f36b616231ab09931f7c9.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4372287_jpg.rf.a12fdb6c6130cefc7e909f6f1b3a48ca.jpg: 640x640 2 lizards, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4374807_jpg.rf.69d25f34e1ced97d7296c004862df0e6.jpg: 640x640 2 lizards, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4375248_jpg.rf.9852b228a9994e75ffe16eeb2f3b1d69.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4375299_jpg.rf.34ab5f8d1705e42914d24c85cc8f6d07.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4375497_jpg.rf.3c4449531abd27625e797d23aaf2cccb.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4375970_jpg.rf.96490706ecc7f04e4545d2186a7ad0ac.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4379209_jpg.rf.2efa5c16c630dafa540c341c64b97246.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4379551_jpg.rf.c3b6f1967cb7669f42b38e3b84d862bf.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4380022_jpg.rf.7cac445c6e05ece4e594c2f2bce67152.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4380581_jpg.rf.a2f4667cd009e791c2f94089cbccc8bb.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4380999_jpg.rf.0240c487bbe8e02d5651ba08433a70cd.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4381640_jpg.rf.552aa78d9994c9ec7c3e65fb64f33c33.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4381714_jpg.rf.b75d420becebc19ff8e1ad38de0c31bb.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4381826_jpg.rf.8c3ded20d393d8343faa6fc9e11d610b.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4381977_jpg.rf.91223a76606a895399bc81a42f6c0b64.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4381982_jpg.rf.5b27238cf557c3aa6ecc781e4b185c68.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4382934_jpg.rf.5ee90896a49ba017a15031bb80c0f8ff.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4384716_jpg.rf.ba6de19c39d92b5c3c6ae8b3a8471864.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4385564_jpg.rf.be71d96f3ec89ac4702959afdab67d5f.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4386025_jpg.rf.1cc5e5cc3b3abc94d4b6617436db6f32.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4386395_jpg.rf.04b9cb0591dc87542ecac23f4a32d914.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4388342_jpg.rf.cf565b6b7948d4160966ef13849cf37d.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4388757_jpg.rf.143db4378140b11019efe3f5fdf7b775.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4389006_jpg.rf.d08ce18a28faa699608eb42bf7213097.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4389492_jpg.rf.42cd6a39c8d4c493dfbecf694d1ee17d.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4389518_jpg.rf.b0e775e96bd5cb91d2517d0c7263f5a2.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4390116_jpg.rf.f66efa139d878e8e29f99977f02c7ad5.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4390554_jpg.rf.33d5ec553a34f7e8d3a646de30cbbfef.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4393527_jpg.rf.6a151aa67815563a2c01c23d315bde48.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4394033_jpg.rf.e2f9fdf1ecc5624113a115ab16ab8b2c.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4394036_jpg.rf.39169c60ae558e0894797bf6d01a18d8.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4394160_jpg.rf.19d112cf08ab7259e69fa543e80965df.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4394525_jpg.rf.8c1f52d34e9397afb53445e222e53c74.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4394910_jpg.rf.9700ad04d5c9b2309997ddb149bde2f2.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4397099_jpg.rf.8cc8be0cd47269279dc2d881a581a614.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4398377_jpg.rf.e8d6994dc2b7a61bc2d54648c101f940.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4401097_jpg.rf.50933da527986e6a90439ee77075325c.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4401157_jpg.rf.77b7c28061e930b74f20a05b4bcb3f8b.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_440189_jpg.rf.cbbcc4ba62f87c421f2790699e2b70ac.jpg: 640x640 2 lizards, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_4404034_jpg.rf.98e7c75dfa866aa206e0bc837e4e0635.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_441179_jpg.rf.27502e859d906494b995705728b825ae.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_442047_jpg.rf.641e0ea74ff951608488957fef9ea4f5.jpg: 640x640 2 lizards, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_44482_jpg.rf.12b6e5a3436416a484fbea28ceb1d131.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_445333_jpg.rf.87e8fbb8804d35f0d41f5fe4bef45fd0.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_447315_jpg.rf.32271fc1341391acea0cc313c111c618.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_449785_jpg.rf.940da124f14ba79472324e6032d40189.jpg: 640x640 2 lizards, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_451605_jpg.rf.6fb67c2b626e3215af255570e8c4d508.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_454632_jpg.rf.4b96b66d9eb029dde31a1554e1814810.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_454647_jpg.rf.2b1c8dc3087535b957cbdb2361ff093d.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_459273_jpg.rf.3a03fa7feac148c4eeb2ac1d41cc52e2.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_459487_jpg.rf.9af9327608144a8139a34db5763cc274.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_460586_jpg.rf.47a81d7e2de6047b31f63bf9a669a82c.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_460604_jpg.rf.10616a7dbed4c74ff17e5e34267c33d4.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_462497_jpg.rf.29fc07e27da448503d2723eecb6b0585.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_46249_jpg.rf.0f97923125ec4b3a99d5bdb608319804.jpg: 640x640 2 lizards, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_463574_jpg.rf.3d8f78c44aee39a246f8a9e3279f4738.jpg: 640x640 (no detections), 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_463592_jpg.rf.075df55cbfa0a98b65fe1a70defaf02c.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_473877_jpg.rf.f10e1622f82b686550084d3b5f389964.jpg: 640x640 2 lizards, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_476159_jpg.rf.cb7a4c43a0d443de2c5ffe4ca78ccaa2.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_485276_jpg.rf.65a474548da11559d6a35de231560f1f.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_493595_jpg.rf.27a63766000f73c4e118cda84fb440b1.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_493597_jpg.rf.a8c878da14216680623b9fb05b59e36f.jpg: 640x640 2 lizards, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_49465_jpg.rf.f98da8e3d78df87893408222fb4a8998.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_496417_jpg.rf.0885913cb155c61c9efbb83e077aa1a2.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_496436_jpg.rf.f86f12b5ed181145fdea83cbfa10a11e.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_496493_jpg.rf.3a47b1abf47eda3e179f7365d340bed3.jpg: 640x640 (no detections), 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_499249_jpg.rf.bb1bc395d7dcb07c7034052e64be178e.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_499811_jpg.rf.27ecb9c7ce9fc988fe653cf5a8c98d98.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_499821_jpg.rf.addb5a25ebee89ba82d82082576d2479.jpg: 640x640 1 lizard, 2.6ms\n",
      "Speed: 0.8ms preprocess, 2.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_499871_jpg.rf.051cffcf40a50a8950c47068e10a3db5.jpg: 640x640 1 lizard, 2.4ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_499894_jpg.rf.fad4b796566d05dc925d4f18081c3ea6.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_499960_jpg.rf.93f4cd1e230b379bf6f29a9f2878dc71.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_500644_jpg.rf.eb7099ed6815318ce3479c7a9ead650d.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_502234_jpg.rf.3a7300029cce5e47982ba040696761e3.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_502385_jpg.rf.38fb4123ee145ef9ace2d499cbf18a44.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_502973_jpg.rf.00dd8130359befdb10d41b4b7bfde7a8.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_503432_jpg.rf.59d3d7b7576d0ee5ed3b10d4c59586af.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_503466_jpg.rf.b2a5f1524a1fd390a41f252202803bfb.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_503482_jpg.rf.404871063ec4c30833b9de874f238a9a.jpg: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_503484_jpg.rf.9e6f5dbf2e9b9d1158d872d7a47547ab.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_503487_jpg.rf.04cb1ca6bfa625c4986461d7771354b3.jpg: 640x640 2 lizards, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_503489_jpg.rf.a7ad9f71c0410eb44f53d965eb926d23.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_503492_jpg.rf.eac8c1e6ca654f14c56008a0670ce337.jpg: 640x640 (no detections), 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_503500_jpg.rf.20e53f1f21cc5528561089669ec3cbe5.jpg: 640x640 (no detections), 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_503502_jpg.rf.475fd40de2e557858841d237f45ff767.jpg: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_50394_jpg.rf.11996722dc5edd7d4bb49516db18b8fc.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_504825_jpg.rf.5f6fc65f633dc8d468685a66f90b0130.jpg: 640x640 (no detections), 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_504827_jpg.rf.4d2b5cf4d04578f79c5a2652f1ffdd69.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_505559_jpg.rf.fafc781974f617ab8e9daabaa4efc5e6.jpg: 640x640 (no detections), 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "missed detection bb confidence: tensor([], device='cuda:0')\n",
      "\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_506491_jpg.rf.2848bbce84f7a65b78fdd5657277e1bb.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_506500_jpg.rf.71f7220881670a2e89c2d4a67cab4110.jpg: 640x640 2 lizards, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_51320_jpg.rf.b09b2fd6ebc5a3925a8ce4adccb2f7b4.jpg: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "class label: green_anole\n",
      "\n",
      "image 1/1 /storage/ice1/6/5/wchia7/Anole_classifier/Spring_2025/../Dataset/yolo_training/florida_five_anole_10000/test/images/36514_51431_jpg.rf.86be6d484bc2f12be1652974e3b70e9a.jpg: 640x640 2 lizards, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Missed Detections: \n",
      " {'bark_anole': 15, 'brown_anole': 11, 'crested_anole': 7, 'green_anole': 9, 'knight_anole': 14}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pipeline_eval import OD_inference\n",
    "\n",
    "ODmodel_path = \"./runs/detect/train_yolov8n_v2/weights/best.pt\"\n",
    "\n",
    "test_folder_path = \"../Dataset/yolo_training/florida_five_anole_10000/test\"\n",
    "dest_folder_path = \"../Dataset/yolo_training/inference\"\n",
    "\n",
    "OD_inference(ODmodel_path, test_folder_path, dest_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cropping Image\n",
    "Will utilize cropping API to crop images in folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cropping Source: ../Dataset/yolo_training/inference/run_20250503_023554/lizard_detection/bark_anole. Saving to ../Dataset/yolo_training/inference/run_20250503_023554/cropped_image/bark_anole\n",
      "\n",
      "Cropped image count: 181\n",
      "Images successfully cropped, resized and saved to ../Dataset/yolo_training/inference/run_20250503_023554/cropped_image/bark_anole\n",
      "Cropping Source: ../Dataset/yolo_training/inference/run_20250503_023554/lizard_detection/brown_anole. Saving to ../Dataset/yolo_training/inference/run_20250503_023554/cropped_image/brown_anole\n",
      "\n",
      "Cropped image count: 186\n",
      "Images successfully cropped, resized and saved to ../Dataset/yolo_training/inference/run_20250503_023554/cropped_image/brown_anole\n",
      "Cropping Source: ../Dataset/yolo_training/inference/run_20250503_023554/lizard_detection/crested_anole. Saving to ../Dataset/yolo_training/inference/run_20250503_023554/cropped_image/crested_anole\n",
      "\n",
      "Cropped image count: 189\n",
      "Images successfully cropped, resized and saved to ../Dataset/yolo_training/inference/run_20250503_023554/cropped_image/crested_anole\n",
      "Cropping Source: ../Dataset/yolo_training/inference/run_20250503_023554/lizard_detection/green_anole. Saving to ../Dataset/yolo_training/inference/run_20250503_023554/cropped_image/green_anole\n",
      "\n",
      "Cropped image count: 187\n",
      "Images successfully cropped, resized and saved to ../Dataset/yolo_training/inference/run_20250503_023554/cropped_image/green_anole\n",
      "Cropping Source: ../Dataset/yolo_training/inference/run_20250503_023554/lizard_detection/knight_anole. Saving to ../Dataset/yolo_training/inference/run_20250503_023554/cropped_image/knight_anole\n",
      "\n",
      "Cropped image count: 184\n",
      "Images successfully cropped, resized and saved to ../Dataset/yolo_training/inference/run_20250503_023554/cropped_image/knight_anole\n"
     ]
    }
   ],
   "source": [
    "from pipeline_eval import crop_image_individual_anole\n",
    "\n",
    "src_folder_path = \"../Dataset/yolo_training/inference/run_20250503_023554/lizard_detection\"\n",
    "dest_folder_path = \"../Dataset/yolo_training/inference/run_20250503_023554/cropped_image\"\n",
    "resize = (384, 384)\n",
    "coord_type = \"xyxy\"\n",
    "\n",
    "crop_image_individual_anole(src_folder_path, dest_folder_path, resize, coord_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run inference from Classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"image-classification\", \"swin-base-patch4-window12-384-finetuned-lizard-class-swin-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04d195d247ca43a99c80cb7883d1cede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/927 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "769d36fa9ec04aad85135b5451644c3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0/927 [00:00<?, ?files/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb1ce0a3012540f8a7f9ff0257c8d6ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "cropped_dataset = load_dataset(\"../Dataset/yolo_training/inference/run_20250503_023554/cropped_image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = cropped_dataset[\"train\"] #Have to get from train b/c there is only 1 folder in cropped image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_image = image[\"image\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'bark_anole', 'score': 0.9995412826538086},\n",
       " {'label': 'crested_anole', 'score': 0.00044674609671346843},\n",
       " {'label': 'brown_anole', 'score': 7.2053217081702314e-06},\n",
       " {'label': 'green_anole', 'score': 3.1463248433283297e-06},\n",
       " {'label': 'knight_anole', 'score': 1.8368094742982066e-06}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(target_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9374325782092773,\n",
       " 'total_time_in_seconds': 12.61808353709057,\n",
       " 'samples_per_second': 73.46599008281287,\n",
       " 'latency_in_seconds': 0.0136117406009607}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from evaluate import evaluator\n",
    "\n",
    "task_evaluator = evaluator(\"image-classification\")\n",
    "\n",
    "eval_results = task_evaluator.compute(\n",
    "    model_or_pipeline=pipe,\n",
    "    data=test_dataset,\n",
    "    metric= \"accuracy\",\n",
    "    label_mapping=pipe.model.config.label2id\n",
    ")\n",
    "\n",
    "eval_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation with Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    }
   ],
   "source": [
    "# Get class names mapping\n",
    "label_names = test_dataset.features[\"label\"].names\n",
    "\n",
    "# Create a mapping from label names to indices\n",
    "label_to_idx = {name: idx for idx, name in enumerate(label_names)}\n",
    "\n",
    "# Prepare predictions and references\n",
    "def predict_image(image):\n",
    "    preds = pipe(image)\n",
    "    name = preds[0][\"label\"]\n",
    "    idx = label_to_idx[name]\n",
    "    return idx  # Get the top prediction\n",
    "\n",
    "# Get predicted labels\n",
    "predictions_int = [predict_image(item[\"image\"]) for item in test_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ground truth labels\n",
    "references_int = [item[\"label\"] for item in test_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check predictions / ground truth labels\n",
    "references_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'confusion_matrix': array([[169,   1,   5,   1,   5],\n",
      "       [  2, 168,  13,   2,   1],\n",
      "       [  6,   7, 175,   1,   0],\n",
      "       [  0,   5,   1, 179,   2],\n",
      "       [  1,   2,   0,   3, 178]])}\n"
     ]
    }
   ],
   "source": [
    "import evaluate \n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = evaluate.load(\"confusion_matrix\")\n",
    "results = conf_matrix.compute(predictions=predictions_int, references=references_int)\n",
    "\n",
    "# Print confusion matrix results\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute f1-score, precision and recall for each Anole class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: bark_anole\n",
      "  Precision: 0.9494\n",
      "  Recall: 0.9337\n",
      "  F1-score: 0.9415\n",
      "------------------------------\n",
      "Class: brown_anole\n",
      "  Precision: 0.9180\n",
      "  Recall: 0.9032\n",
      "  F1-score: 0.9106\n",
      "------------------------------\n",
      "Class: crested_anole\n",
      "  Precision: 0.9021\n",
      "  Recall: 0.9259\n",
      "  F1-score: 0.9138\n",
      "------------------------------\n",
      "Class: green_anole\n",
      "  Precision: 0.9624\n",
      "  Recall: 0.9572\n",
      "  F1-score: 0.9598\n",
      "------------------------------\n",
      "Class: knight_anole\n",
      "  Precision: 0.9570\n",
      "  Recall: 0.9674\n",
      "  F1-score: 0.9622\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Compute precision, recall, and F1-score\n",
    "metric = evaluate.combine([\"precision\", \"recall\", 'f1'])\n",
    "prf_results = metric.compute(predictions=predictions_int, references=references_int, average=None)  # No averaging, get per-class metrics\n",
    "\n",
    "# Print per-class precision, recall, and F1-score\n",
    "for i, class_name in enumerate(label_names):\n",
    "    print(f\"Class: {class_name}\")\n",
    "    print(f\"  Precision: {prf_results['precision'][i]:.4f}\")\n",
    "    print(f\"  Recall: {prf_results['recall'][i]:.4f}\")\n",
    "    print(f\"  F1-score: {prf_results['f1'][i]:.4f}\")\n",
    "    print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Confusion Matrix (Absolute Numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Convert to numpy array\n",
    "conf_matrix = np.array(results[\"confusion_matrix\"])\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=test_dataset.features[\"label\"].names, yticklabels=test_dataset.features[\"label\"].names)\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Confusion Matrix (Normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Convert to numpy array\n",
    "conf_matrix = np.array(results[\"confusion_matrix\"])\n",
    "\n",
    "conf_matrix_normalized = conf_matrix.astype(\"float\") / conf_matrix.sum(axis=1, keepdims=True)\n",
    "\n",
    "# Ensure NaNs (if any row sums to 0) are replaced with 0\n",
    "conf_matrix_normalized = np.nan_to_num(conf_matrix_normalized)\n",
    "\n",
    "# Plot the normalized confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    conf_matrix_normalized * 100,  # Convert to percentage\n",
    "    annot=True, fmt=\".2f\", cmap=\"Blues\",\n",
    "    xticklabels=label_names, yticklabels=label_names\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.title(\"Normalized Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run custom script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 lizard, 2.5ms\n",
      "Speed: 5.8ms preprocess, 2.5ms inference, 72.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.8ms\n",
      "Speed: 0.9ms preprocess, 2.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.8ms\n",
      "Speed: 0.8ms preprocess, 2.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.8ms\n",
      "Speed: 0.8ms preprocess, 2.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.8ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.8ms\n",
      "Speed: 0.9ms preprocess, 2.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.8ms\n",
      "Speed: 0.8ms preprocess, 2.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.9ms\n",
      "Speed: 0.9ms preprocess, 2.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 lizards, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.8ms\n",
      "Speed: 0.9ms preprocess, 2.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 1.0ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 1.0ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.8ms\n",
      "Speed: 0.8ms preprocess, 2.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.8ms\n",
      "Speed: 0.9ms preprocess, 2.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 1.5ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.8ms\n",
      "Speed: 0.8ms preprocess, 2.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 1.0ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.8ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.8ms\n",
      "Speed: 0.9ms preprocess, 2.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 lizards, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 1.0ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 3 lizards, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.8ms\n",
      "Speed: 0.9ms preprocess, 2.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.8ms\n",
      "Speed: 0.9ms preprocess, 2.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.8ms\n",
      "Speed: 0.8ms preprocess, 2.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.8ms\n",
      "Speed: 0.9ms preprocess, 2.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.8ms\n",
      "Speed: 0.8ms preprocess, 2.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.8ms\n",
      "Speed: 0.8ms preprocess, 2.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.3ms\n",
      "Speed: 0.7ms preprocess, 2.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.8ms\n",
      "Speed: 0.9ms preprocess, 2.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 lizards, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.8ms\n",
      "Speed: 0.9ms preprocess, 2.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.8ms\n",
      "Speed: 0.8ms preprocess, 2.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.8ms\n",
      "Speed: 0.9ms preprocess, 2.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.8ms\n",
      "Speed: 1.4ms preprocess, 2.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.4ms\n",
      "Speed: 0.7ms preprocess, 2.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.8ms\n",
      "Speed: 0.8ms preprocess, 2.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.8ms\n",
      "Speed: 0.8ms preprocess, 2.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.8ms\n",
      "Speed: 0.9ms preprocess, 2.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 lizards, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 2.7ms\n",
      "Speed: 0.9ms preprocess, 2.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.5ms\n",
      "Speed: 0.8ms preprocess, 2.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.8ms\n",
      "Speed: 0.9ms preprocess, 2.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 lizard, 2.7ms\n",
      "Speed: 0.8ms preprocess, 2.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Saved evaluation results to ../Dataset/yolo_training/inference/run_20250504_112054/eval_results.csv\n",
      "\n",
      "Classification Report (IoU ≥ 0.5 matched):\n",
      "/home/hice1/wchia7/scratch/conda_venvs/lizard_class/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hice1/wchia7/scratch/conda_venvs/lizard_class/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hice1/wchia7/scratch/conda_venvs/lizard_class/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9540    0.8300    0.8877       200\n",
      "           1     0.9186    0.7900    0.8495       200\n",
      "           2     0.9135    0.8450    0.8779       200\n",
      "           3     0.9556    0.8600    0.9053       200\n",
      "           4     0.9818    0.8100    0.8877       200\n",
      "           5     0.0000    0.0000    0.0000         0\n",
      "\n",
      "    accuracy                         0.8270      1000\n",
      "   macro avg     0.7873    0.6892    0.7347      1000\n",
      "weighted avg     0.9447    0.8270    0.8816      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python pipeline_custom_eval.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded evaluation results from ../Dataset/yolo_training/inference/run_20250504_112054/eval_results.csv\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of classes in 'y_true' (5) not equal to the number of classes in 'y_score' (2).You can provide a list of all known classes by assigning it to the `labels` parameter.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot find results path\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m \u001b[43mtop_k_accuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/scratch/conda_venvs/lizard_class/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
      "File \u001b[0;32m~/scratch/conda_venvs/lizard_class/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:2008\u001b[0m, in \u001b[0;36mtop_k_accuracy_score\u001b[0;34m(y_true, y_score, k, normalize, sample_weight, labels)\u001b[0m\n\u001b[1;32m   2005\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(classes)\n\u001b[1;32m   2007\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m!=\u001b[39m y_score_n_classes:\n\u001b[0;32m-> 2008\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2009\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of classes in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) not equal \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2010\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto the number of classes in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_score\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_score_n_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2011\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can provide a list of all known classes by assigning it \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2012\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto the `labels` parameter.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2013\u001b[0m         )\n\u001b[1;32m   2014\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2015\u001b[0m     labels \u001b[38;5;241m=\u001b[39m column_or_1d(labels)\n",
      "\u001b[0;31mValueError\u001b[0m: Number of classes in 'y_true' (5) not equal to the number of classes in 'y_score' (2).You can provide a list of all known classes by assigning it to the `labels` parameter."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "RESULTS_PATH = \"../Dataset/yolo_training/inference/run_20250504_112054/eval_results.csv\"\n",
    "\n",
    "if os.path.exists(RESULTS_PATH):\n",
    "    df = pd.read_csv(RESULTS_PATH)\n",
    "    y_true_all = df[\"y_true\"].tolist()\n",
    "    y_pred_all = df[\"y_pred\"].tolist()\n",
    "    print(f\"Loaded evaluation results from {RESULTS_PATH}\")\n",
    "else:\n",
    "    print(\"Cannot find results path\")\n",
    "\n",
    "# Compute top-1 accuracy\n",
    "top1_acc = accuracy_score(y_true_all, y_pred_all)\n",
    "print(f\"Top-1 Accuracy: {top1_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded evaluation results from ../Dataset/yolo_training/inference/run_20250504_112054/eval_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4078111/283827126.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  cm_normalized = cm.astype(\"float\") / cm.sum(axis=1, keepdims=True)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os\n",
    "\n",
    "NUM_CLASSES = 5\n",
    "MISSED_CLASS_ID = 5\n",
    "ALL_CLASSES = list(range(NUM_CLASSES)) + [MISSED_CLASS_ID]\n",
    "CLASS_NAMES = [\"Bark Anole\", \"Brown Anole\", \"Crested Anole\", \"Green Anole\", \"Knight Anole\"] + [\"Missed\"]\n",
    "\n",
    "RESULTS_PATH = \"../Dataset/yolo_training/inference/run_20250504_112054/eval_results.csv\"\n",
    "\n",
    "if os.path.exists(RESULTS_PATH):\n",
    "    df = pd.read_csv(RESULTS_PATH)\n",
    "    y_true_all = df[\"y_true\"].tolist()\n",
    "    y_pred_all = df[\"y_pred\"].tolist()\n",
    "    print(f\"Loaded evaluation results from {RESULTS_PATH}\")\n",
    "else:\n",
    "    print(\"Cannot find results path\")\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true_all, y_pred_all, labels=ALL_CLASSES)\n",
    "\n",
    "# Normalize by rows (true labels)\n",
    "cm_normalized = cm.astype(\"float\") / cm.sum(axis=1, keepdims=True)\n",
    "cm_normalized = np.nan_to_num(cm_normalized)  # Avoid NaNs\n",
    "\n",
    "# Plot heatmap\n",
    "cm_df = pd.DataFrame(cm_normalized, index=CLASS_NAMES, columns=CLASS_NAMES)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_df, annot=True, fmt=\".2f\", cmap=\"Blues\")\n",
    "plt.title(\"Normalized Confusion Matrix (Including Missed Detections)\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot heatmap\n",
    "cm_df = pd.DataFrame(cm, index=CLASS_NAMES, columns=CLASS_NAMES)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_df, annot=True, fmt=\".0f\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix (Including Missed Detections)\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:lizard_class]",
   "language": "python",
   "name": "conda-env-lizard_class-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
